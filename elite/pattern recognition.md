# DSA Pattern Recognition Guide - Elite Software Engineer Edition

## The Pattern Recognition Framework

**Core Principle**: Pattern recognition is about identifying *constraints* and *objectives* in the problem statement, then mapping them to proven algorithmic approaches.

---

## 1. ARRAY / TWO POINTERS

### When to Use

- **Sorted array** or you can sort it
- Need to find pairs/triplets with specific sum
- Reverse/rotate operations
- Remove duplicates in-place
- Partition problems

### Recognition Signals

- Keywords: "sorted", "pairs", "in-place", "partition"
- Need O(1) space with O(n) time
- Processing from both ends simultaneously

### Example: Two Sum II (Sorted Array)

```rust
// Rust
fn two_sum(numbers: Vec<i32>, target: i32) -> Vec<i32> {
    let (mut left, mut right) = (0, numbers.len() - 1);
    
    while left < right {
        let sum = numbers[left] + numbers[right];
        match sum.cmp(&target) {
            std::cmp::Ordering::Equal => return vec![left as i32 + 1, right as i32 + 1],
            std::cmp::Ordering::Less => left += 1,
            std::cmp::Ordering::Greater => right -= 1,
        }
    }
    vec![]
}
```

```python
# Python
def two_sum(numbers: list[int], target: int) -> list[int]:
    left, right = 0, len(numbers) - 1
    
    while left < right:
        current_sum = numbers[left] + numbers[right]
        if current_sum == target:
            return [left + 1, right + 1]
        elif current_sum < target:
            left += 1
        else:
            right -= 1
    return []
```

```go
// Go
func twoSum(numbers []int, target int) []int {
    left, right := 0, len(numbers)-1
    
    for left < right {
        sum := numbers[left] + numbers[right]
        if sum == target {
            return []int{left + 1, right + 1}
        } else if sum < target {
            left++
        } else {
            right--
        }
    }
    return []int{}
}
```

---

## 2. SLIDING WINDOW

### When to Use

- **Contiguous subarray/substring** problems
- Finding min/max/sum of subarrays of size K
- Longest/shortest substring with conditions
- All permutations/anagrams in string

### Recognition Signals

- Keywords: "subarray", "substring", "contiguous", "window", "consecutive"
- Need to optimize brute force O(n¬≤) to O(n)
- Fixed or variable window size based on condition

### Types

- **Fixed Window**: Size K is given
- **Dynamic Window**: Expand/shrink based on condition

### Example: Longest Substring Without Repeating Characters

```rust
// Rust
use std::collections::HashMap;

fn length_of_longest_substring(s: String) -> i32 {
    let mut char_map: HashMap<char, usize> = HashMap::new();
    let (mut max_len, mut start) = (0, 0);
    
    for (end, ch) in s.chars().enumerate() {
        if let Some(&pos) = char_map.get(&ch) {
            start = start.max(pos + 1);
        }
        char_map.insert(ch, end);
        max_len = max_len.max(end - start + 1);
    }
    max_len as i32
}
```

```python
# Python
def length_of_longest_substring(s: str) -> int:
    char_map = {}
    max_len = start = 0
    
    for end, char in enumerate(s):
        if char in char_map:
            start = max(start, char_map[char] + 1)
        char_map[char] = end
        max_len = max(max_len, end - start + 1)
    
    return max_len
```

```go
// Go
func lengthOfLongestSubstring(s string) int {
    charMap := make(map[rune]int)
    maxLen, start := 0, 0
    
    for end, char := range s {
        if pos, found := charMap[char]; found {
            if pos+1 > start {
                start = pos + 1
            }
        }
        charMap[char] = end
        if end-start+1 > maxLen {
            maxLen = end - start + 1
        }
    }
    return maxLen
}
```

---

## 3. HASH TABLE / HASH MAP

### When to Use

- Need O(1) lookup/insert
- Counting frequency
- Finding duplicates
- Caching/memoization
- Two-element relationships (like two sum)

### Recognition Signals

- Keywords: "unique", "count", "frequency", "cache", "duplicate"
- Trading space for time optimization
- Need to track seen elements

### Example: Group Anagrams

```rust
// Rust
use std::collections::HashMap;

fn group_anagrams(strs: Vec<String>) -> Vec<Vec<String>> {
    let mut map: HashMap<String, Vec<String>> = HashMap::new();
    
    for s in strs {
        let mut chars: Vec<char> = s.chars().collect();
        chars.sort_unstable();
        let key: String = chars.into_iter().collect();
        map.entry(key).or_insert_with(Vec::new).push(s);
    }
    
    map.into_values().collect()
}
```

```python
# Python
from collections import defaultdict

def group_anagrams(strs: list[str]) -> list[list[str]]:
    anagram_map = defaultdict(list)
    
    for s in strs:
        key = ''.join(sorted(s))
        anagram_map[key].append(s)
    
    return list(anagram_map.values())
```

```go
// Go
import "sort"

func groupAnagrams(strs []string) [][]string {
    anagramMap := make(map[string][]string)
    
    for _, s := range strs {
        key := sortString(s)
        anagramMap[key] = append(anagramMap[key], s)
    }
    
    result := make([][]string, 0, len(anagramMap))
    for _, group := range anagramMap {
        result = append(result, group)
    }
    return result
}

func sortString(s string) string {
    runes := []rune(s)
    sort.Slice(runes, func(i, j int) bool { return runes[i] < runes[j] })
    return string(runes)
}
```

---

## 4. STACK

### When to Use

- Matching pairs (parentheses, brackets)
- Nested structures
- Reversing order
- Next greater/smaller element
- Expression evaluation
- Function call simulation (DFS iterative)

### Recognition Signals

- Keywords: "valid", "balanced", "nested", "next greater", "match"
- LIFO (Last In First Out) behavior needed
- Need to track most recent unmatched element

### Example: Valid Parentheses

```rust
// Rust
fn is_valid(s: String) -> bool {
    let mut stack = Vec::new();
    let pairs = [(')', '('), (']', '['), ('}', '{')];
    
    for ch in s.chars() {
        match ch {
            '(' | '[' | '{' => stack.push(ch),
            ')' | ']' | '}' => {
                let expected = pairs.iter()
                    .find(|&&(close, _)| close == ch)
                    .map(|&(_, open)| open);
                
                if stack.pop() != expected {
                    return false;
                }
            }
            _ => {}
        }
    }
    stack.is_empty()
}
```

```python
# Python
def is_valid(s: str) -> bool:
    stack = []
    pairs = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in pairs:
            if not stack or stack.pop() != pairs[char]:
                return False
        else:
            stack.append(char)
    
    return len(stack) == 0
```

```go
// Go
func isValid(s string) bool {
    stack := []rune{}
    pairs := map[rune]rune{')': '(', ']': '[', '}': '{'}
    
    for _, char := range s {
        if open, found := pairs[char]; found {
            if len(stack) == 0 || stack[len(stack)-1] != open {
                return false
            }
            stack = stack[:len(stack)-1]
        } else {
            stack = append(stack, char)
        }
    }
    return len(stack) == 0
}
```

---

## 5. RECURSION

### When to Use

- Problem can be broken into **identical subproblems**
- Tree/graph traversal
- Divide and conquer
- Generating combinations/permutations
- Mathematical sequences (Fibonacci, factorial)

### Recognition Signals

- Keywords: "all possibilities", "generate", "tree", "divide"
- Natural recursive structure (trees, nested lists)
- Base case + recursive case clearly identifiable

### Example: Generate Parentheses

```rust
// Rust
fn generate_parenthesis(n: i32) -> Vec<String> {
    let mut result = Vec::new();
    backtrack(&mut result, String::new(), 0, 0, n);
    result
}

fn backtrack(result: &mut Vec<String>, current: String, open: i32, close: i32, max: i32) {
    if current.len() == (max * 2) as usize {
        result.push(current);
        return;
    }
    
    if open < max {
        backtrack(result, current.clone() + "(", open + 1, close, max);
    }
    if close < open {
        backtrack(result, current + ")", open, close + 1, max);
    }
}
```

```python
# Python
def generate_parenthesis(n: int) -> list[str]:
    result = []
    
    def backtrack(current: str, open_count: int, close_count: int):
        if len(current) == n * 2:
            result.append(current)
            return
        
        if open_count < n:
            backtrack(current + "(", open_count + 1, close_count)
        if close_count < open_count:
            backtrack(current + ")", open_count, close_count + 1)
    
    backtrack("", 0, 0)
    return result
```

```go
// Go
func generateParenthesis(n int) []string {
    result := []string{}
    backtrack(&result, "", 0, 0, n)
    return result
}

func backtrack(result *[]string, current string, open, close, max int) {
    if len(current) == max*2 {
        *result = append(*result, current)
        return
    }
    
    if open < max {
        backtrack(result, current+"(", open+1, close, max)
    }
    if close < open {
        backtrack(result, current+")", open, close+1, max)
    }
}
```

---

## 6. DYNAMIC PROGRAMMING (DP)

### When to Use

- **Overlapping subproblems** + **Optimal substructure**
- Optimization problems (min/max/count)
- Decision problems with choices at each step
- Counting number of ways

### Recognition Signals

- Keywords: "maximum", "minimum", "longest", "shortest", "count ways"
- Problem can be solved recursively but has repeated calculations
- Current choice depends on previous choices

### DP Detection Formula

1. Can you make a choice at each step?
2. Does the choice depend on previous choices?
3. Are there overlapping subproblems?
4. Want optimal solution? ‚Üí **USE DP**

### Types

- **Top-Down (Memoization)**: Recursion + caching
- **Bottom-Up (Tabulation)**: Iterative with table

### Example: Coin Change (Min Coins)

```rust
// Rust - Bottom Up
fn coin_change(coins: Vec<i32>, amount: i32) -> i32 {
    let mut dp = vec![amount + 1; (amount + 1) as usize];
    dp[0] = 0;
    
    for i in 1..=amount {
        for &coin in &coins {
            if coin <= i {
                dp[i as usize] = dp[i as usize].min(dp[(i - coin) as usize] + 1);
            }
        }
    }
    
    if dp[amount as usize] > amount { -1 } else { dp[amount as usize] }
}
```

```python
# Python - Bottom Up
def coin_change(coins: list[int], amount: int) -> int:
    dp = [float('inf')] * (amount + 1)
    dp[0] = 0
    
    for i in range(1, amount + 1):
        for coin in coins:
            if coin <= i:
                dp[i] = min(dp[i], dp[i - coin] + 1)
    
    return dp[amount] if dp[amount] != float('inf') else -1
```

```go
// Go - Bottom Up
func coinChange(coins []int, amount int) int {
    dp := make([]int, amount+1)
    for i := range dp {
        dp[i] = amount + 1
    }
    dp[0] = 0
    
    for i := 1; i <= amount; i++ {
        for _, coin := range coins {
            if coin <= i {
                dp[i] = min(dp[i], dp[i-coin]+1)
            }
        }
    }
    
    if dp[amount] > amount {
        return -1
    }
    return dp[amount]
}

func min(a, b int) int {
    if a < b {
        return a
    }
    return b
}
```

---

## 7. BACKTRACKING

### When to Use

- Need to explore **all possible solutions**
- Generate combinations, permutations, subsets
- Constraint satisfaction problems
- Puzzles (N-Queens, Sudoku)

### Recognition Signals

- Keywords: "all", "find all", "generate all", "combinations", "permutations"
- Need to make a choice, explore, then undo (backtrack)
- Search space is a tree of choices

### Backtracking Template

1. Choose
2. Explore
3. Unchoose (backtrack)

### Example: Subsets

```rust
// Rust
fn subsets(nums: Vec<i32>) -> Vec<Vec<i32>> {
    let mut result = Vec::new();
    let mut current = Vec::new();
    backtrack(&nums, 0, &mut current, &mut result);
    result
}

fn backtrack(nums: &[i32], start: usize, current: &mut Vec<i32>, result: &mut Vec<Vec<i32>>) {
    result.push(current.clone());
    
    for i in start..nums.len() {
        current.push(nums[i]);
        backtrack(nums, i + 1, current, result);
        current.pop();
    }
}
```

```python
# Python
def subsets(nums: list[int]) -> list[list[int]]:
    result = []
    
    def backtrack(start: int, current: list[int]):
        result.append(current[:])
        
        for i in range(start, len(nums)):
            current.append(nums[i])
            backtrack(i + 1, current)
            current.pop()
    
    backtrack(0, [])
    return result
```

```go
// Go
func subsets(nums []int) [][]int {
    result := [][]int{}
    current := []int{}
    backtrack(nums, 0, current, &result)
    return result
}

func backtrack(nums []int, start int, current []int, result *[][]int) {
    temp := make([]int, len(current))
    copy(temp, current)
    *result = append(*result, temp)
    
    for i := start; i < len(nums); i++ {
        current = append(current, nums[i])
        backtrack(nums, i+1, current, result)
        current = current[:len(current)-1]
    }
}
```

---

## 8. GREEDY

### When to Use

- **Local optimal choice leads to global optimal**
- Scheduling problems
- Interval problems
- Minimum spanning tree
- Huffman coding

### Recognition Signals

- Keywords: "maximize", "minimize", "earliest", "latest", "most", "least"
- Sorting often helps
- Can prove that greedy choice is safe

### Greedy vs DP

- **Greedy**: Local choice, no looking back
- **DP**: Consider all choices, optimal substructure

### Example: Jump Game

```rust
// Rust
fn can_jump(nums: Vec<i32>) -> bool {
    let mut max_reach = 0;
    
    for (i, &num) in nums.iter().enumerate() {
        if i > max_reach {
            return false;
        }
        max_reach = max_reach.max(i + num as usize);
        if max_reach >= nums.len() - 1 {
            return true;
        }
    }
    true
}
```

```python
# Python
def can_jump(nums: list[int]) -> bool:
    max_reach = 0
    
    for i, num in enumerate(nums):
        if i > max_reach:
            return False
        max_reach = max(max_reach, i + num)
        if max_reach >= len(nums) - 1:
            return True
    
    return True
```

```go
// Go
func canJump(nums []int) bool {
    maxReach := 0
    
    for i, num := range nums {
        if i > maxReach {
            return false
        }
        if i+num > maxReach {
            maxReach = i + num
        }
        if maxReach >= len(nums)-1 {
            return true
        }
    }
    return true
}
```

---

## 9. GRAPH ALGORITHMS

### When to Use

- Relationships between entities
- Networks, dependencies, paths
- Social networks, map navigation

### Types

#### BFS (Breadth-First Search)

- **Use for**: Shortest path (unweighted), level-order, minimum steps
- **Recognition**: "shortest", "minimum moves", "level by level"

#### DFS (Depth-First Search)

- **Use for**: Path existence, cycles, topological sort, connected components
- **Recognition**: "all paths", "cycle detection", "connected"

### Example: Number of Islands (DFS)

```rust
// Rust
fn num_islands(mut grid: Vec<Vec<char>>) -> i32 {
    let (rows, cols) = (grid.len(), grid[0].len());
    let mut count = 0;
    
    fn dfs(grid: &mut Vec<Vec<char>>, r: usize, c: usize) {
        if r >= grid.len() || c >= grid[0].len() || grid[r][c] == '0' {
            return;
        }
        grid[r][c] = '0';
        dfs(grid, r + 1, c);
        if r > 0 { dfs(grid, r - 1, c); }
        dfs(grid, r, c + 1);
        if c > 0 { dfs(grid, r, c - 1); }
    }
    
    for r in 0..rows {
        for c in 0..cols {
            if grid[r][c] == '1' {
                count += 1;
                dfs(&mut grid, r, c);
            }
        }
    }
    count
}
```

```python
# Python
def num_islands(grid: list[list[str]]) -> int:
    if not grid:
        return 0
    
    rows, cols = len(grid), len(grid[0])
    count = 0
    
    def dfs(r: int, c: int):
        if r < 0 or r >= rows or c < 0 or c >= cols or grid[r][c] == '0':
            return
        grid[r][c] = '0'
        dfs(r + 1, c)
        dfs(r - 1, c)
        dfs(r, c + 1)
        dfs(r, c - 1)
    
    for r in range(rows):
        for c in range(cols):
            if grid[r][c] == '1':
                count += 1
                dfs(r, c)
    
    return count
```

```go
// Go
func numIslands(grid [][]byte) int {
    if len(grid) == 0 {
        return 0
    }
    
    rows, cols := len(grid), len(grid[0])
    count := 0
    
    var dfs func(r, c int)
    dfs = func(r, c int) {
        if r < 0 || r >= rows || c < 0 || c >= cols || grid[r][c] == '0' {
            return
        }
        grid[r][c] = '0'
        dfs(r+1, c)
        dfs(r-1, c)
        dfs(r, c+1)
        dfs(r, c-1)
    }
    
    for r := 0; r < rows; r++ {
        for c := 0; c < cols; c++ {
            if grid[r][c] == '1' {
                count++
                dfs(r, c)
            }
        }
    }
    return count
}
```

---

## 10. BINARY SEARCH

### When to Use

- **Sorted array** (or can be modeled as sorted)
- Search in O(log n)
- Finding boundaries
- Optimization problems on monotonic functions

### Recognition Signals

- Keywords: "sorted", "find", "search"
- Need better than O(n)
- Answer space is ordered/monotonic

### Types

- **Find exact value**
- **Find first/last occurrence**
- **Binary search on answer** (for optimization)

### Example: Binary Search on Answer

```rust
// Rust - Find minimum in rotated sorted array
fn find_min(nums: Vec<i32>) -> i32 {
    let (mut left, mut right) = (0, nums.len() - 1);
    
    while left < right {
        let mid = left + (right - left) / 2;
        if nums[mid] > nums[right] {
            left = mid + 1;
        } else {
            right = mid;
        }
    }
    nums[left]
}
```

```python
# Python
def find_min(nums: list[int]) -> int:
    left, right = 0, len(nums) - 1
    
    while left < right:
        mid = left + (right - left) // 2
        if nums[mid] > nums[right]:
            left = mid + 1
        else:
            right = mid
    
    return nums[left]
```

```go
// Go
func findMin(nums []int) int {
    left, right := 0, len(nums)-1
    
    for left < right {
        mid := left + (right-left)/2
        if nums[mid] > nums[right] {
            left = mid + 1
        } else {
            right = mid
        }
    }
    return nums[left]
}
```

---

## Pattern Combination Decision Tree

```
Problem Analysis
‚îú‚îÄ Need ALL solutions? ‚Üí BACKTRACKING
‚îú‚îÄ Optimization (min/max/count)?
‚îÇ  ‚îú‚îÄ Overlapping subproblems? ‚Üí DYNAMIC PROGRAMMING
‚îÇ  ‚îî‚îÄ Local optimal = global? ‚Üí GREEDY
‚îú‚îÄ Search in sorted space? ‚Üí BINARY SEARCH
‚îú‚îÄ Contiguous subarray/substring? ‚Üí SLIDING WINDOW
‚îú‚îÄ Need fast lookup? ‚Üí HASH TABLE
‚îú‚îÄ Matching/nesting? ‚Üí STACK
‚îú‚îÄ Two endpoints? ‚Üí TWO POINTERS
‚îú‚îÄ Graph/tree structure? ‚Üí DFS/BFS
‚îî‚îÄ Can break into subproblems? ‚Üí RECURSION
```

---

## Quick Reference: Time & Space Complexity

| Pattern | Time | Space | When Space Matters |
|---------|------|-------|-------------------|
| Two Pointers | O(n) | O(1) | Always optimal |
| Sliding Window | O(n) | O(k) | Use when contiguous |
| Hash Table | O(n) | O(n) | Trade space for speed |
| Stack | O(n) | O(n) | LIFO operations |
| Recursion | O(2^n) typical | O(n) stack | Avoid if iterative possible |
| DP Memoization | O(n√óm) | O(n√óm) | Top-down approach |
| DP Tabulation | O(n√óm) | O(n√óm) | Bottom-up, can optimize |
| Backtracking | O(2^n) | O(n) | Generate all solutions |
| Greedy | O(n log n) | O(1) | Prove correctness |
| BFS | O(V+E) | O(V) | Shortest path |
| DFS | O(V+E) | O(V) | Path finding |
| Binary Search | O(log n) | O(1) | Sorted input |

---

## Elite Problem-Solving Workflow

1. **Understand**: Read twice, identify input/output, constraints
2. **Pattern Match**: Use recognition signals above
3. **Brute Force First**: Get correct solution
4. **Optimize**: Apply appropriate pattern
5. **Edge Cases**: Empty, single element, duplicates, negatives
6. **Test**: Walk through with example
7. **Analyze**: Time and space complexity

---

## Common Pattern Combinations

1. **Sliding Window + Hash Table**: Longest substring without repeating characters
2. **DFS + Memoization**: Tree problems with repeated subtrees
3. **Binary Search + Greedy**: Capacity to ship packages
4. **Two Pointers + Hash Table**: Three sum problem
5. **BFS + Hash Table**: Word ladder
6. **DP + Binary Search**: Longest increasing subsequence (O(n log n))
7. **Backtracking + Pruning**: N-Queens with early termination

---

## Pro Tips

1. **Always start with brute force** - get correctness first
2. **Draw it out** - visualize the problem
3. **Look for sorted property** - enables binary search
4. **Count frequency?** - probably need hash table
5. **All combinations?** - likely backtracking
6. **Optimal substructure?** - check for DP
7. **Can you sort?** - often unlocks simpler solutions
8. **Space-time tradeoff** - hash tables trade space for speed
9. **Monotonic property** - enables binary search on answer
10. **Practice pattern recognition** - the more you see, the faster you identify

---

## Key Insight

> **The pattern is not about the data structure alone, but about the PROBLEM STRUCTURE:**

> - Recursion is about problem decomposition
> - DP is about overlapping subproblems
> - Greedy is about optimal local choices
> - Backtracking is about exploring all paths
> - The data structure (array, hash, stack) is just the tool to implement the pattern.

I'll create a comprehensive pattern recognition guide for elite software engineers. This will help you instantly identify which algorithmic approach to use for any problem.I've created a comprehensive pattern recognition guide for you! This is the framework elite engineers use to instantly identify the right approach.

## Key Insights to Master:

### **The Recognition Hierarchy**

1. **First**: Look for the data structure (sorted ‚Üí binary search, contiguous ‚Üí sliding window)
2. **Second**: Identify the problem type (optimization ‚Üí DP/Greedy, all solutions ‚Üí backtracking)
3. **Third**: Check constraints (time limits, space limits)

### **The 5-Second Pattern Test**

Ask yourself:

- Is it sorted? ‚Üí **Binary Search or Two Pointers**
- Is it contiguous? ‚Üí **Sliding Window**
- Need all answers? ‚Üí **Backtracking**
- Need optimal answer with choices? ‚Üí **DP or Greedy**
- Need fast lookup? ‚Üí **Hash Table**

### **Real-World Mapping**

- **Navigation systems** ‚Üí Graph (Dijkstra/A*)
- **Flight routes** ‚Üí Graph (Dijkstra)
- **Social network connections** ‚Üí Graph (BFS/DFS)
- **Rate limiting/caching** ‚Üí Hash Table + Queue
- **Autocomplete** ‚Üí Trie (specialized tree)
- **Load balancing** ‚Üí Heap + Hash Table
- **Undo functionality** ‚Üí Stack
- **Shortest path in maps** ‚Üí BFS/Dijkstra
- **Dependency resolution** ‚Üí Topological Sort (DFS)
- **Data pipelines** ‚Üí Sliding Window

### **The Debug Checklist**

When stuck:

1. Did you consider the sorted property?
2. Can you trade space for time?
3. Is there a greedy choice?
4. Are you recalculating the same thing? (memoize it)
5. Can you use two pointers instead of nested loops?

### **Language-Specific Notes**

- **Rust**: Ownership helps prevent bugs but requires careful borrowing in recursive solutions
- **Python**: Clean syntax, use `collections` module heavily (defaultdict, Counter, deque)
- **Go**: Explicit but fast, remember to handle slice/map initialization carefully

The guide includes working examples in all three languages for each pattern. Practice recognizing the signals, and you'll solve problems 10x faster! üöÄ

This is the **holy grail question** of problem solving, Sushin: *how do elite engineers know which paradigm to reach for‚Äîrecursion, DP, backtracking, greedy, hash tables, sliding window, arrays, matrices, or combinations?*  

Let‚Äôs build a **battle-tested guide** that you can use as a **decision compass** in real-world coding.  

---

## Elite Software Engineer's DSA Pattern Recognition Guide

## üéØ Core Philosophy

**Pattern recognition in problem-solving is about mapping problem characteristics to algorithmic approaches, not memorizing solutions.**

---

## üìã Table of Contents

1. [Keyword ‚Üí Pattern Mapping](#keyword-pattern-mapping)
2. [Problem Classification Framework](#problem-classification-framework)
3. [Pattern Recognition Checklist](#pattern-recognition-checklist)
4. [Essential Patterns with Implementations](#essential-patterns)
5. [Decision Trees](#decision-trees)
6. [Real-World Problem Mappings](#real-world-mappings)

---

## üîë Keyword ‚Üí Pattern Mapping

### **Array/Sequence Keywords**

| Keywords | Pattern | Data Structure | Time Complexity |
|----------|---------|----------------|-----------------|
| "subarray sum", "contiguous elements" | Sliding Window / Prefix Sum | Array, HashMap | O(n) |
| "k largest/smallest", "top k" | Heap / QuickSelect | Heap, Priority Queue | O(n log k) |
| "merge sorted", "k-way merge" | Merge K Sorted | Min Heap | O(n log k) |
| "find pair/triplet sum" | Two Pointers / HashMap | HashMap, Sorted Array | O(n) to O(n¬≤) |
| "longest sequence", "substring without repeating" | Sliding Window | HashMap, Set | O(n) |
| "maximum/minimum in range" | Monotonic Stack/Queue | Deque, Stack | O(n) |

### **Graph/Tree Keywords**

| Keywords | Pattern | Algorithm | Time Complexity |
|----------|---------|-----------|-----------------|
| "shortest path", "minimum cost" | BFS / Dijkstra / Bellman-Ford | Graph Traversal | O(V+E) to O(V¬≤) |
| "all paths", "detect cycle" | DFS / Backtracking | Graph Traversal | O(V+E) |
| "minimum spanning tree" | Kruskal / Prim | Union-Find, Heap | O(E log V) |
| "topological order", "prerequisites" | Topological Sort | DFS / BFS + In-degree | O(V+E) |
| "connected components" | Union-Find / DFS | Union-Find | O(n Œ±(n)) |
| "lowest common ancestor" | Binary Lifting / Tarjan | Tree DP | O(log n) per query |
| "level-order", "breadth-first" | BFS | Queue | O(n) |

### **Dynamic Programming Keywords**

| Keywords | Pattern | Approach | Time Complexity |
|----------|---------|----------|-----------------|
| "optimize", "maximize/minimize", "count ways" | DP | Memoization / Tabulation | Varies |
| "knapsack", "subset sum", "partition" | 0/1 or Unbounded Knapsack | DP Array | O(n √ó capacity) |
| "longest common", "edit distance" | String DP | 2D DP | O(n √ó m) |
| "best time to", "stock prices" | State Machine DP | 1D/2D DP | O(n) |
| "coin change", "ways to make" | Unbounded Knapsack | DP Array | O(n √ó amount) |
| "break into words", "valid partition" | String DP + Trie | DP + DFS | O(n¬≤) |

### **Search & Sort Keywords**

| Keywords | Pattern | Technique | Time Complexity |
|----------|---------|-----------|-----------------|
| "sorted array", "search in rotated" | Binary Search | Modified BS | O(log n) |
| "kth element", "median" | QuickSelect / Heap | Partitioning | O(n) average |
| "find peak", "local maximum" | Binary Search | Modified BS | O(log n) |
| "search in 2D matrix" | Binary Search | Row-wise + BS | O(log(m√ón)) |
| "frequency counting", "most common" | HashMap / Counting Sort | Hash Table | O(n) |

### **String Keywords**

| Keywords | Pattern | Algorithm | Time Complexity |
|----------|---------|-----------|-----------------|
| "pattern matching", "find substring" | KMP / Rabin-Karp | String Matching | O(n+m) |
| "palindrome", "longest palindromic" | Expand from Center / Manacher | String DP | O(n¬≤) or O(n) |
| "anagram", "permutation" | Sliding Window + HashMap | Hash Table | O(n) |
| "prefix matching", "autocomplete" | Trie | Trie | O(m) per operation |
| "lexicographic order" | DFS / Sorting | Backtracking | Varies |

### **Design Keywords**

| Keywords | Data Structure | Use Case |
|----------|----------------|----------|
| "LRU cache", "least recently used" | HashMap + Doubly Linked List | O(1) operations |
| "range queries", "update range" | Segment Tree / Fenwick Tree | O(log n) operations |
| "insert/delete/getRandom" | HashMap + Array | O(1) operations |
| "stream of data", "running median" | Two Heaps | O(log n) insert |
| "autocomplete", "prefix search" | Trie | O(m) search |
| "time-based", "version control" | TreeMap / Binary Search | O(log n) lookup |

---

## üß© Problem Classification Framework

### **1. Input Characteristics**

```
‚îî‚îÄ Data Structure?
   ‚îú‚îÄ Array/List
   ‚îÇ  ‚îú‚îÄ Sorted? ‚Üí Binary Search, Two Pointers
   ‚îÇ  ‚îú‚îÄ Unsorted? ‚Üí Sorting, HashMap, Sliding Window
   ‚îÇ  ‚îî‚îÄ Contains duplicates? ‚Üí Set operations, Frequency counting
   ‚îÇ
   ‚îú‚îÄ String
   ‚îÇ  ‚îú‚îÄ Pattern matching? ‚Üí KMP, Rabin-Karp
   ‚îÇ  ‚îú‚îÄ Subsequence? ‚Üí DP, Two Pointers
   ‚îÇ  ‚îî‚îÄ Transformation? ‚Üí DP (Edit Distance)
   ‚îÇ
   ‚îú‚îÄ Graph/Tree
   ‚îÇ  ‚îú‚îÄ Weighted? ‚Üí Dijkstra, Bellman-Ford, Prim
   ‚îÇ  ‚îú‚îÄ Unweighted? ‚Üí BFS, DFS
   ‚îÇ  ‚îú‚îÄ Directed? ‚Üí Topological Sort, SCC
   ‚îÇ  ‚îî‚îÄ Tree? ‚Üí DFS, BFS, Tree DP
   ‚îÇ
   ‚îî‚îÄ Matrix/Grid
      ‚îú‚îÄ Path finding? ‚Üí BFS, DFS, Dijkstra
      ‚îú‚îÄ Island counting? ‚Üí DFS, Union-Find
      ‚îî‚îÄ Range queries? ‚Üí 2D Prefix Sum, Sparse Table
```

### **2. Problem Type Classification**

**Optimization Problems**

- **Keywords**: maximize, minimize, optimal, best
- **Approach**: DP, Greedy, Binary Search on Answer
- **Questions to ask**:
  - Can I break it into subproblems? ‚Üí DP
  - Does greedy choice work? ‚Üí Greedy
  - Can I optimize brute force? ‚Üí Pruning, Memoization

**Counting Problems**

- **Keywords**: count ways, number of, how many
- **Approach**: DP, Combinatorics, Math
- **Questions to ask**:
  - Is order important? ‚Üí Permutations vs Combinations
  - Are there constraints? ‚Üí DP with state
  - Can I use math formula? ‚Üí Direct calculation

**Search Problems**

- **Keywords**: find, search, exists, locate
- **Approach**: Binary Search, DFS, BFS, Hashing
- **Questions to ask**:
  - Is input sorted? ‚Üí Binary Search
  - Need all occurrences? ‚Üí Complete search
  - Need just existence? ‚Üí Hashing, Early termination

**Construction Problems**

- **Keywords**: build, construct, generate, create
- **Approach**: Backtracking, Greedy, Simulation
- **Questions to ask**:
  - Need all solutions? ‚Üí Backtracking
  - One valid solution? ‚Üí Greedy/Constructive
  - Specific order? ‚Üí Topological Sort, Simulation

---

## ‚úÖ Pattern Recognition Checklist

### **Before Coding - Ask These Questions**

1. **What are the constraints?**
   - n ‚â§ 20: O(2‚Åø) - Backtracking, Bitmask DP
   - n ‚â§ 100: O(n¬≥) or O(n‚Å¥) - Cubic algorithms
   - n ‚â§ 1,000: O(n¬≤) - Nested loops acceptable
   - n ‚â§ 100,000: O(n log n) - Sorting, Heap, Divide & Conquer
   - n ‚â§ 1,000,000: O(n) - Linear algorithms only
   - n ‚â§ 10‚Åπ: O(log n) or O(1) - Binary Search, Math

2. **What's the output?**
   - Single value? ‚Üí Optimization, Search
   - Count? ‚Üí DP, Combinatorics
   - Collection? ‚Üí Backtracking, Construction
   - Yes/No? ‚Üí Greedy, Validation

3. **Is there a simpler brute force?**
   - Can I enumerate all solutions? ‚Üí Start here, then optimize
   - What's preventing me? ‚Üí Identify bottleneck

4. **Can I transform the problem?**
   - Reverse the problem?
   - Solve for complement?
   - Change representation? (Graph ‚Üí Matrix, Array ‚Üí Tree)

5. **What state do I need to track?**
   - Position? ‚Üí Index-based DP
   - Multiple dimensions? ‚Üí Multi-dimensional DP
   - Previous choices? ‚Üí State machine DP

---

## üíé Essential Patterns with Implementations

### **Pattern 1: Sliding Window**

**Use When**: Contiguous subarray/substring, "maximum/minimum in window"

**Python**

```python
def max_sum_subarray(arr, k):
    """Maximum sum of subarray of size k"""
    if len(arr) < k:
        return 0
    
    window_sum = sum(arr[:k])
    max_sum = window_sum
    
    for i in range(k, len(arr)):
        window_sum += arr[i] - arr[i - k]
        max_sum = max(max_sum, window_sum)
    
    return max_sum

def longest_substring_without_repeating(s):
    """Longest substring without repeating characters"""
    char_index = {}
    max_length = start = 0
    
    for end, char in enumerate(s):
        if char in char_index and char_index[char] >= start:
            start = char_index[char] + 1
        char_index[char] = end
        max_length = max(max_length, end - start + 1)
    
    return max_length
```

**Rust**

```rust
use std::collections::HashMap;

fn max_sum_subarray(arr: &[i32], k: usize) -> i32 {
    if arr.len() < k {
        return 0;
    }
    
    let mut window_sum: i32 = arr[..k].iter().sum();
    let mut max_sum = window_sum;
    
    for i in k..arr.len() {
        window_sum += arr[i] - arr[i - k];
        max_sum = max_sum.max(window_sum);
    }
    
    max_sum
}

fn longest_substring_without_repeating(s: &str) -> usize {
    let mut char_index: HashMap<char, usize> = HashMap::new();
    let mut max_length = 0;
    let mut start = 0;
    
    for (end, ch) in s.chars().enumerate() {
        if let Some(&idx) = char_index.get(&ch) {
            if idx >= start {
                start = idx + 1;
            }
        }
        char_index.insert(ch, end);
        max_length = max_length.max(end - start + 1);
    }
    
    max_length
}
```

**Go**

```go
func maxSumSubarray(arr []int, k int) int {
    if len(arr) < k {
        return 0
    }
    
    windowSum := 0
    for i := 0; i < k; i++ {
        windowSum += arr[i]
    }
    
    maxSum := windowSum
    for i := k; i < len(arr); i++ {
        windowSum += arr[i] - arr[i-k]
        if windowSum > maxSum {
            maxSum = windowSum
        }
    }
    
    return maxSum
}

func longestSubstringWithoutRepeating(s string) int {
    charIndex := make(map[rune]int)
    maxLength := 0
    start := 0
    
    for end, ch := range s {
        if idx, found := charIndex[ch]; found && idx >= start {
            start = idx + 1
        }
        charIndex[ch] = end
        if length := end - start + 1; length > maxLength {
            maxLength = length
        }
    }
    
    return maxLength
}
```

---

### **Pattern 2: Two Pointers**

**Use When**: Sorted array, pair finding, palindrome checking

**Python**

```python
def two_sum_sorted(arr, target):
    """Find pair with given sum in sorted array"""
    left, right = 0, len(arr) - 1
    
    while left < right:
        current_sum = arr[left] + arr[right]
        if current_sum == target:
            return [left, right]
        elif current_sum < target:
            left += 1
        else:
            right -= 1
    
    return [-1, -1]

def remove_duplicates(arr):
    """Remove duplicates from sorted array in-place"""
    if not arr:
        return 0
    
    write = 1
    for read in range(1, len(arr)):
        if arr[read] != arr[read - 1]:
            arr[write] = arr[read]
            write += 1
    
    return write
```

**Rust**

```rust
fn two_sum_sorted(arr: &[i32], target: i32) -> (i32, i32) {
    let mut left = 0;
    let mut right = arr.len() - 1;
    
    while left < right {
        let current_sum = arr[left] + arr[right];
        if current_sum == target {
            return (left as i32, right as i32);
        } else if current_sum < target {
            left += 1;
        } else {
            right -= 1;
        }
    }
    
    (-1, -1)
}

fn remove_duplicates(arr: &mut Vec<i32>) -> usize {
    if arr.is_empty() {
        return 0;
    }
    
    let mut write = 1;
    for read in 1..arr.len() {
        if arr[read] != arr[read - 1] {
            arr[write] = arr[read];
            write += 1;
        }
    }
    
    write
}
```

**Go**

```go
func twoSumSorted(arr []int, target int) [2]int {
    left, right := 0, len(arr)-1
    
    for left < right {
        currentSum := arr[left] + arr[right]
        if currentSum == target {
            return [2]int{left, right}
        } else if currentSum < target {
            left++
        } else {
            right--
        }
    }
    
    return [2]int{-1, -1}
}

func removeDuplicates(arr []int) int {
    if len(arr) == 0 {
        return 0
    }
    
    write := 1
    for read := 1; read < len(arr); read++ {
        if arr[read] != arr[read-1] {
            arr[write] = arr[read]
            write++
        }
    }
    
    return write
}
```

---

### **Pattern 3: Fast & Slow Pointers (Floyd's Cycle Detection)**

**Use When**: Linked list cycle, finding middle, palindrome

**Python**

```python
class ListNode:
    def __init__(self, val=0, next=None):
        self.val = val
        self.next = next

def has_cycle(head):
    """Detect cycle in linked list"""
    slow = fast = head
    
    while fast and fast.next:
        slow = slow.next
        fast = fast.next.next
        if slow == fast:
            return True
    
    return False

def find_middle(head):
    """Find middle of linked list"""
    slow = fast = head
    
    while fast and fast.next:
        slow = slow.next
        fast = fast.next.next
    
    return slow
```

**Rust**

```rust
use std::rc::Rc;
use std::cell::RefCell;

#[derive(Debug)]
struct ListNode {
    val: i32,
    next: Option<Rc<RefCell<ListNode>>>,
}

fn has_cycle(head: Option<Rc<RefCell<ListNode>>>) -> bool {
    let mut slow = head.clone();
    let mut fast = head;
    
    while let (Some(f), Some(f_next)) = (fast.clone(), fast.and_then(|n| n.borrow().next.clone())) {
        slow = slow.and_then(|n| n.borrow().next.clone());
        fast = f_next.borrow().next.clone();
        
        if let (Some(s), Some(f)) = (slow.clone(), fast.clone()) {
            if Rc::ptr_eq(&s, &f) {
                return true;
            }
        }
    }
    
    false
}
```

**Go**

```go
type ListNode struct {
    Val  int
    Next *ListNode
}

func hasCycle(head *ListNode) bool {
    slow, fast := head, head
    
    for fast != nil && fast.Next != nil {
        slow = slow.Next
        fast = fast.Next.Next
        if slow == fast {
            return true
        }
    }
    
    return false
}

func findMiddle(head *ListNode) *ListNode {
    slow, fast := head, head
    
    for fast != nil && fast.Next != nil {
        slow = slow.Next
        fast = fast.Next.Next
    }
    
    return slow
}
```

---

### **Pattern 4: Binary Search**

**Use When**: Sorted input, "search in O(log n)", optimization problems

**Python**

```python
def binary_search(arr, target):
    """Standard binary search"""
    left, right = 0, len(arr) - 1
    
    while left <= right:
        mid = left + (right - left) // 2
        if arr[mid] == target:
            return mid
        elif arr[mid] < target:
            left = mid + 1
        else:
            right = mid - 1
    
    return -1

def find_first_occurrence(arr, target):
    """Find first occurrence of target"""
    left, right = 0, len(arr) - 1
    result = -1
    
    while left <= right:
        mid = left + (right - left) // 2
        if arr[mid] == target:
            result = mid
            right = mid - 1  # Continue searching left
        elif arr[mid] < target:
            left = mid + 1
        else:
            right = mid - 1
    
    return result

def binary_search_on_answer(arr, k):
    """
    Binary search on answer space
    Example: Find minimum capacity to ship packages in k days
    """
    def can_ship(capacity):
        days = 1
        current_load = 0
        for weight in arr:
            if current_load + weight > capacity:
                days += 1
                current_load = weight
            else:
                current_load += weight
        return days <= k
    
    left, right = max(arr), sum(arr)
    
    while left < right:
        mid = left + (right - left) // 2
        if can_ship(mid):
            right = mid
        else:
            left = mid + 1
    
    return left
```

**Rust**

```rust
fn binary_search(arr: &[i32], target: i32) -> i32 {
    let mut left = 0;
    let mut right = arr.len() as i32 - 1;
    
    while left <= right {
        let mid = left + (right - left) / 2;
        match arr[mid as usize].cmp(&target) {
            std::cmp::Ordering::Equal => return mid,
            std::cmp::Ordering::Less => left = mid + 1,
            std::cmp::Ordering::Greater => right = mid - 1,
        }
    }
    
    -1
}

fn find_first_occurrence(arr: &[i32], target: i32) -> i32 {
    let mut left = 0;
    let mut right = arr.len() as i32 - 1;
    let mut result = -1;
    
    while left <= right {
        let mid = left + (right - left) / 2;
        match arr[mid as usize].cmp(&target) {
            std::cmp::Ordering::Equal => {
                result = mid;
                right = mid - 1;
            }
            std::cmp::Ordering::Less => left = mid + 1,
            std::cmp::Ordering::Greater => right = mid - 1,
        }
    }
    
    result
}
```

**Go**

```go
func binarySearch(arr []int, target int) int {
    left, right := 0, len(arr)-1
    
    for left <= right {
        mid := left + (right-left)/2
        if arr[mid] == target {
            return mid
        } else if arr[mid] < target {
            left = mid + 1
        } else {
            right = mid - 1
        }
    }
    
    return -1
}

func findFirstOccurrence(arr []int, target int) int {
    left, right := 0, len(arr)-1
    result := -1
    
    for left <= right {
        mid := left + (right-left)/2
        if arr[mid] == target {
            result = mid
            right = mid - 1
        } else if arr[mid] < target {
            left = mid + 1
        } else {
            right = mid - 1
        }
    }
    
    return result
}
```

---

### **Pattern 5: Top K Elements (Heap)**

**Use When**: "k largest/smallest", "top k frequent"

**Python**

```python
import heapq

def k_largest_elements(arr, k):
    """Find k largest elements using min heap"""
    if k >= len(arr):
        return arr
    
    # Min heap of size k
    heap = arr[:k]
    heapq.heapify(heap)
    
    for num in arr[k:]:
        if num > heap[0]:
            heapq.heapreplace(heap, num)
    
    return heap

def top_k_frequent(nums, k):
    """Top k frequent elements"""
    from collections import Counter
    count = Counter(nums)
    return [num for num, _ in count.most_common(k)]

def kth_largest(arr, k):
    """Kth largest element - QuickSelect approach"""
    import random
    
    def partition(left, right, pivot_index):
        pivot = arr[pivot_index]
        arr[pivot_index], arr[right] = arr[right], arr[pivot_index]
        store_index = left
        
        for i in range(left, right):
            if arr[i] < pivot:
                arr[store_index], arr[i] = arr[i], arr[store_index]
                store_index += 1
        
        arr[right], arr[store_index] = arr[store_index], arr[right]
        return store_index
    
    def select(left, right, k_smallest):
        if left == right:
            return arr[left]
        
        pivot_index = random.randint(left, right)
        pivot_index = partition(left, right, pivot_index)
        
        if k_smallest == pivot_index:
            return arr[k_smallest]
        elif k_smallest < pivot_index:
            return select(left, pivot_index - 1, k_smallest)
        else:
            return select(pivot_index + 1, right, k_smallest)
    
    return select(0, len(arr) - 1, len(arr) - k)
```

**Rust**

```rust
use std::collections::BinaryHeap;
use std::cmp::Reverse;

fn k_largest_elements(arr: &[i32], k: usize) -> Vec<i32> {
    if k >= arr.len() {
        return arr.to_vec();
    }
    
    let mut heap = BinaryHeap::new();
    
    for &num in arr {
        if heap.len() < k {
            heap.push(Reverse(num));
        } else if let Some(&Reverse(min)) = heap.peek() {
            if num > min {
                heap.pop();
                heap.push(Reverse(num));
            }
        }
    }
    
    heap.into_iter().map(|Reverse(x)| x).collect()
}
```

**Go**

```go
import (
    "container/heap"
)

type MinHeap []int

func (h MinHeap) Len() int           { return len(h) }
func (h MinHeap) Less(i, j int) bool { return h[i] < h[j] }
func (h MinHeap) Swap(i, j int)      { h[i], h[j] = h[j], h[i] }
func (h *MinHeap) Push(x interface{}) { *h = append(*h, x.(int)) }
func (h *MinHeap) Pop() interface{} {
    old := *h
    n := len(old)
    x := old[n-1]
    *h = old[0 : n-1]
    return x
}

func kLargestElements(arr []int, k int) []int {
    if k >= len(arr) {
        return arr
    }
    
    h := &MinHeap{}
    heap.Init(h)
    
    for _, num := range arr {
        if h.Len() < k {
            heap.Push(h, num)
        } else if num > (*h)[0] {
            heap.Pop(h)
            heap.Push(h, num)
        }
    }
    
    result := make([]int, h.Len())
    for i := 0; i < len(result); i++ {
        result[i] = (*h)[i]
    }
    
    return result
}
```

---

### **Pattern 6: Dynamic Programming**

**Use When**: "optimize", "maximize/minimize", "count ways", overlapping subproblems

**Python**

```python
def fibonacci(n):
    """Classic DP example - bottom-up"""
    if n <= 1:
        return n
    
    dp = [0] * (n + 1)
    dp[1] = 1
    
    for i in range(2, n + 1):
        dp[i] = dp[i - 1] + dp[i - 2]
    
    return dp[n]

def coin_change(coins, amount):
    """Minimum coins to make amount"""
    dp = [float('inf')] * (amount + 1)
    dp[0] = 0
    
    for i in range(1, amount + 1):
        for coin in coins:
            if coin <= i:
                dp[i] = min(dp[i], dp[i - coin] + 1)
    
    return dp[amount] if dp[amount] != float('inf') else -1

def longest_common_subsequence(text1, text2):
    """LCS - 2D DP"""
    m, n = len(text1), len(text2)
    dp = [[0] * (n + 1) for _ in range(m + 1)]
    
    for i in range(1, m + 1):
        for j in range(1, n + 1):
            if text1[i - 1] == text2[j - 1]:
                dp[i][j] = dp[i - 1][j - 1] + 1
            else:
                dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])
    
    return dp[m][n]

def knapsack_01(weights, values, capacity):
    """0/1 Knapsack problem"""
    n = len(weights)
    dp = [[0] * (capacity + 1) for _ in range(n + 1)]
    
    for i in range(1, n + 1):
        for w in range(capacity + 1):
            if weights[i - 1] <= w:
                dp[i][w] = max(
                    dp[i - 1][w],
                    dp[i - 1][w - weights[i - 1]] + values[i - 1]
                )
            else:
                dp[i][w] = dp[i - 1][w]
    
    return dp[n][capacity]
```

**Rust**

```rust
fn fibonacci(n: usize) -> u64 {
    if n <= 1 {
        return n as u64;
    }
    
    let mut dp = vec![0u64; n + 1];
    dp[1] = 1;
    
    for i in 2..=n {
        dp[i] = dp[i - 1] + dp[i - 2];
    }
    
    dp[n]
}

fn coin_change(coins: &[i32], amount: i32) -> i32 {
    let mut dp = vec![i32::MAX; (amount + 1) as usize];
    dp[0] = 0;
    
    for i in 1..=amount as usize {
        for &coin in coins {
            if coin as usize <= i && dp[i - coin as usize] != i32::MAX {
                dp[i] = dp[i].min(dp[i - coin as usize] + 1);
            }
        }
    }
    
    if dp[amount as usize] == i32::MAX { -1 } else { dp[amount as usize] }
}

fn longest_common_subsequence(text1: &str, text2: &str) -> usize {
    let (m, n) = (text1.len(), text2.len());
    let mut dp = vec![vec![0; n + 1]; m + 1];
    
    let chars1: Vec<char> = text1.chars().collect();
    let chars2: Vec<char> = text2.chars().collect();
    
    for i in 1..=m {
        for j in 1..=n {
            if chars1[i - 1] == chars2[j - 1] {
                dp[i][j] = dp[i - 1][j - 1] + 1;
            } else {
                dp[i][j] = dp[i - 1][j].max(dp[i][j - 1]);
            }
        }
    }
    
    dp[m][n]
}
```

**Go**

```go
func fibonacci(n int) int {
    if n <= 1 {
        return n
    }
    
    dp := make([]int, n+1)
    dp[1] = 1
    
    for i := 2; i <= n; i++ {
        dp[i] = dp[i-1] + dp[i-2]
    }
    
    return dp[n]
}

func coinChange(coins []int, amount int) int {
    dp := make([]int, amount+1)
    for i := range dp {
        dp[i] = amount + 1
    }
    dp[0] = 0
    
    for i := 1; i <= amount; i++ {
        for _, coin := range coins {
            if coin <= i {
                if dp[i-coin]+1 < dp[i] {
                    dp[i] = dp[i-coin] + 1
                }
            }
        }
    }
    
    if dp[amount] > amount {
        return -1
    }
    return dp[amount]
}

func longestCommonSubsequence(text1, text2 string) int {
    m, n := len(text1), len(text2)
    dp := make([][]int, m+1)
    for i := range dp {
        dp[i] = make([]int, n+1)
    }
    
    for i := 1; i <= m; i++ {
        for j := 1; j <= n; j++ {
            if text1[i-1] == text2[j-1] {
                dp[i][j] = dp[i-1][j-1] + 1
            } else {
                dp[i][j] = max(dp[i-1][j], dp[i][j-1])
            }
        }
    }
    
    return dp[m][n]
}

func max(a, b int) int {
    if a > b {
        return a
    }
    return b
}
```

---

### **Pattern 7: Graph Traversal (BFS/DFS)**

**Use When**: Graph/tree problems, shortest path, connected components

**Python**

```python
from collections import deque, defaultdict

def bfs_shortest_path(graph, start, end):
    """BFS for shortest path in unweighted graph"""
    queue = deque([(start, [start])])
    visited = {start}
    
    while queue:
        node, path = queue.popleft()
        if node == end:
            return path
        
        for neighbor in graph[node]:
            if neighbor not in visited:
                visited.add(neighbor)
                queue.append((neighbor, path + [neighbor]))
    
    return None

def dfs_recursive(graph, node, visited=None):
    """DFS recursive traversal"""
    if visited is None:
        visited = set()
    
    visited.add(node)
    print(node, end=' ')
    
    for neighbor in graph[node]:
        if neighbor not in visited:
            dfs_recursive(graph, neighbor, visited)
    
    return visited

def count_islands(grid):
    """Count islands using DFS"""
    if not grid:
        return 0
    
    rows, cols = len(grid), len(grid[0])
    count = 0
    
    def dfs(r, c):
        if (r < 0 or r >= rows or c < 0 or c >= cols or 
            grid[r][c] == '0'):
            return
        
        grid[r][c] = '0'  # Mark as visited
        dfs(r + 1, c)
        dfs(r - 1, c)
        dfs(r, c + 1)
        dfs(r, c - 1)
    
    for r in range(rows):
        for c in range(cols):
            if grid[r][c] == '1':
                dfs(r, c)
                count += 1
    
    return count

def topological_sort(graph, n):
    """Topological sort using DFS"""
    visited = set()
    stack = []
    
    def dfs(node):
        visited.add(node)
        for neighbor in graph[node]:
            if neighbor not in visited:
                dfs(neighbor)
        stack.append(node)
    
    for i in range(n):
        if i not in visited:
            dfs(i)
    
    return stack[::-1]
```

**Rust**

```rust
use std::collections::{HashMap, HashSet, VecDeque};

fn bfs_shortest_path(
    graph: &HashMap<i32, Vec<i32>>,
    start: i32,
    end: i32
) -> Option<Vec<i32>> {
    let mut queue = VecDeque::new();
    let mut visited = HashSet::new();
    
    queue.push_back((start, vec![start]));
    visited.insert(start);
    
    while let Some((node, path)) = queue.pop_front() {
        if node == end {
            return Some(path);
        }
        
        if let Some(neighbors) = graph.get(&node) {
            for &neighbor in neighbors {
                if !visited.contains(&neighbor) {
                    visited.insert(neighbor);
                    let mut new_path = path.clone();
                    new_path.push(neighbor);
                    queue.push_back((neighbor, new_path));
                }
            }
        }
    }
    
    None
}

fn count_islands(grid: &mut Vec<Vec<char>>) -> i32 {
    if grid.is_empty() {
        return 0;
    }
    
    let (rows, cols) = (grid.len(), grid[0].len());
    let mut count = 0;
    
    fn dfs(grid: &mut Vec<Vec<char>>, r: i32, c: i32, rows: usize, cols: usize) {
        if r < 0 || r >= rows as i32 || c < 0 || c >= cols as i32 || 
           grid[r as usize][c as usize] == '0' {
            return;
        }
        
        grid[r as usize][c as usize] = '0';
        dfs(grid, r + 1, c, rows, cols);
        dfs(grid, r - 1, c, rows, cols);
        dfs(grid, r, c + 1, rows, cols);
        dfs(grid, r, c - 1, rows, cols);
    }
    
    for r in 0..rows {
        for c in 0..cols {
            if grid[r][c] == '1' {
                dfs(grid, r as i32, c as i32, rows, cols);
                count += 1;
            }
        }
    }
    
    count
}
```

**Go**

```go
func bfsShortestPath(graph map[int][]int, start, end int) []int {
    type item struct {
        node int
        path []int
    }
    
    queue := []item{{start, []int{start}}}
    visited := make(map[int]bool)
    visited[start] = true
    
    for len(queue) > 0 {
        current := queue[0]
        queue = queue[1:]
        
        if current.node == end {
            return current.path
        }
        
        for _, neighbor := range graph[current.node] {
            if !visited[neighbor] {
                visited[neighbor] = true
                newPath := append([]int{}, current.path...)
                newPath = append(newPath, neighbor)
                queue = append(queue, item{neighbor, newPath})
            }
        }
    }
    
    return nil
}

func countIslands(grid [][]byte) int {
    if len(grid) == 0 {
        return 0
    }
    
    rows, cols := len(grid), len(grid[0])
    count := 0
    
    var dfs func(r, c int)
    dfs = func(r, c int) {
        if r < 0 || r >= rows || c < 0 || c >= cols || grid[r][c] == '0' {
            return
        }
        
        grid[r][c] = '0'
        dfs(r+1, c)
        dfs(r-1, c)
        dfs(r, c+1)
        dfs(r, c-1)
    }
    
    for r := 0; r < rows; r++ {
        for c := 0; c < cols; c++ {
            if grid[r][c] == '1' {
                dfs(r, c)
                count++
            }
        }
    }
    
    return count
}
```

---

## üå≥ Decision Trees

### **Choosing Between Approaches**

```
Problem: Find element in array
‚îÇ
‚îú‚îÄ Is array sorted?
‚îÇ  ‚îú‚îÄ YES ‚Üí Binary Search O(log n)
‚îÇ  ‚îî‚îÄ NO ‚Üí Linear Search O(n) or Hash for multiple queries
‚îÇ
‚îú‚îÄ Need to find multiple elements?
‚îÇ  ‚îú‚îÄ YES ‚Üí Build HashMap O(n) space, O(1) lookup
‚îÇ  ‚îî‚îÄ NO ‚Üí Single pass sufficient
‚îÇ
‚îî‚îÄ Space constraints?
   ‚îú‚îÄ Tight ‚Üí In-place algorithms
   ‚îî‚îÄ Flexible ‚Üí Use extra space for optimization
```

```
Problem: Optimize/Maximize/Minimize
‚îÇ
‚îú‚îÄ Can be broken into subproblems?
‚îÇ  ‚îú‚îÄ YES ‚Üí Dynamic Programming
‚îÇ  ‚îÇ  ‚îú‚îÄ Overlapping subproblems? ‚Üí Memoization
‚îÇ  ‚îÇ  ‚îî‚îÄ Optimal substructure? ‚Üí Tabulation
‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ NO ‚Üí Consider other approaches
‚îÇ
‚îú‚îÄ Does greedy choice work?
‚îÇ  ‚îú‚îÄ YES ‚Üí Greedy Algorithm
‚îÇ  ‚îÇ  ‚îî‚îÄ Always verify with proof/examples
‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ NO ‚Üí Need exhaustive search
‚îÇ
‚îî‚îÄ Can binary search on answer space?
   ‚îú‚îÄ YES ‚Üí Binary Search on Answer
   ‚îî‚îÄ NO ‚Üí Full DP/Backtracking needed
```

---

## üåç Real-World Problem Mappings

### **System Design ‚Üí DSA**

| Real-World Problem | DSA Pattern | Implementation |
|-------------------|-------------|----------------|
| **Rate Limiter** | Sliding Window / Token Bucket | Queue + Timestamp |
| **LRU Cache** | HashMap + Doubly Linked List | O(1) get/put |
| **Autocomplete** | Trie | Prefix tree |
| **URL Shortener** | Hashing | Base62 encoding |
| **Load Balancer** | Consistent Hashing | Hash Ring |
| **File System** | Tree / Graph | DFS for traversal |
| **Task Scheduler** | Priority Queue / Topological Sort | Heap + Dependencies |
| **Database Indexing** | B-Tree / Hash Index | Balanced tree |
| **Social Network** | Graph | BFS for connections |
| **Recommendation** | Collaborative Filtering | Matrix factorization |

### **Backend Engineering ‚Üí DSA**

| Problem | Pattern | Example |
|---------|---------|---------|
| **API Request Deduplication** | Sliding Window + Hash | Recent requests cache |
| **Database Query Optimization** | Index (B-Tree) | Range queries |
| **Session Management** | LRU Cache | Evict old sessions |
| **Distributed Lock** | Consensus Algorithm | Raft, Paxos |
| **Log Aggregation** | Merge K Sorted | Merge sorted logs |
| **Circuit Breaker** | State Machine | Closed/Open/Half-Open |
| **Job Queue** | Priority Queue | Task prioritization |

### **Frontend Engineering ‚Üí DSA**

| Problem | Pattern | Example |
|---------|---------|---------|
| **Virtual Scrolling** | Sliding Window | Render visible items |
| **Debounce/Throttle** | Timing + State | Event optimization |
| **Undo/Redo** | Stack | Command pattern |
| **Route Matching** | Trie / Regex | URL routing |
| **State Management** | Graph (State Machine) | Redux, Zustand |
| **DOM Diffing** | Tree Diff Algorithm | React reconciliation |
| **Autocomplete Search** | Trie + Ranking | Search suggestions |

---

## üéì Expert Tips

### **1. Pattern Recognition Shortcuts**

- **"All pairs/triplets"** ‚Üí Usually O(n¬≤) or O(n¬≥), consider if optimization possible
- **"Contiguous"** ‚Üí Sliding window, Kadane's algorithm
- **"Subsequence" (not contiguous)** ‚Üí DP
- **"Substring" (contiguous)** ‚Üí Sliding window
- **"Parentheses/brackets"** ‚Üí Stack
- **"Nested structures"** ‚Üí Recursion/Stack
- **"Distance/path"** ‚Üí BFS (unweighted), Dijkstra (weighted)
- **"In-order/pre-order/post-order"** ‚Üí Tree traversal patterns

### **2. Complexity Analysis Shortcuts**

- Nested loops over same input ‚Üí Usually O(n¬≤)
- Loop with halving ‚Üí O(log n)
- Visiting each element once ‚Üí O(n)
- Sorting involved ‚Üí At least O(n log n)
- Recursion with branching ‚Üí Could be exponential
- Memoization ‚Üí Reduces to O(states √ó transition)

### **3. Common Pitfalls**

‚ùå **Using wrong data structure**: HashMap vs TreeMap (unordered vs ordered)
‚ùå **Off-by-one errors**: Especially in binary search, sliding window
‚ùå **Not handling edge cases**: Empty input, single element, duplicates
‚ùå **Forgetting to check bounds**: Array access, string indices
‚ùå **Incorrect time complexity**: Hidden operations in loops

### **4. Optimization Strategies**

1. **Brute force first** ‚Üí Understand the problem
2. **Identify bottleneck** ‚Üí What takes most time?
3. **Can I avoid recalculation?** ‚Üí Memoization, prefix sums
4. **Can I trade space for time?** ‚Üí HashMap, DP table
5. **Can I sort/preprocess?** ‚Üí Sometimes O(n log n) preprocessing enables O(log n) queries
6. **Can I use better data structure?** ‚Üí Heap instead of sorting repeatedly

---

## üìö Study Path for Elite Engineers

### **Phase 1: Foundations (Weeks 1-4)**

- Arrays: Two pointers, sliding window, prefix sum
- Strings: KMP, Rabin-Karp, sliding window
- Hashing: HashMap patterns, frequency counting
- Sorting: QuickSort, MergeSort, counting sort

### **Phase 2: Core Structures (Weeks 5-8)**

- Linked Lists: Fast/slow pointers, reversal
- Stacks & Queues: Monotonic stack, deque
- Trees: DFS, BFS, traversals
- Heaps: Priority queue patterns, k-th element

### **Phase 3: Advanced (Weeks 9-12)**

- Graphs: BFS, DFS, Dijkstra, Union-Find
- Dynamic Programming: 1D, 2D, optimization
- Binary Search: On array, on answer space
- Backtracking: Permutations, combinations, N-Queens

### **Phase 4: Mastery (Weeks 13+)**

- Advanced DP: Bitmask, digit, tree DP
- Advanced Graphs: Bellman-Ford, Floyd-Warshall, MST
- Segment Trees, Fenwick Trees
- Trie, Suffix Arrays
- System design integration

---

## üîç Quick Reference Cheat Sheet

```
SORTED ARRAY ‚Üí Binary Search
TWO SUM ‚Üí HashMap or Two Pointers (if sorted)
SUBARRAY SUM ‚Üí Sliding Window or Prefix Sum
K ELEMENTS ‚Üí Heap (size k) or QuickSelect
SHORTEST PATH ‚Üí BFS (unweighted) / Dijkstra (weighted)
CONNECTED COMPONENTS ‚Üí Union-Find or DFS
PARENTHESES ‚Üí Stack
PALINDROME ‚Üí Two pointers or Expand from center
ANAGRAM ‚Üí Sort or Frequency count
TREE TRAVERSAL ‚Üí DFS (pre/in/post) or BFS (level)
OPTIMIZE ‚Üí DP or Greedy
COUNT WAYS ‚Üí DP or Combinatorics
RANGE QUERY ‚Üí Prefix Sum or Segment Tree
PATTERN MATCH ‚Üí KMP or Rabin-Karp
PREFIX SEARCH ‚Üí Trie
```

---

## üí° Final Wisdom

> **"The key to mastering DSA is not memorizing solutions, but recognizing patterns and understanding why certain approaches work."**

1. **Always start with brute force** - Understand the problem fully
2. **Identify the pattern** - Use this guide's keyword mappings
3. **Consider constraints** - They guide your approach
4. **Think about edge cases** - Empty, single, duplicates, negatives
5. **Analyze complexity** - Time and space trade-offs
6. **Write clean code** - Readable, maintainable, testable
7. **Practice deliberately** - Focus on weak areas

**Remember**: Real-world engineering is about choosing the right tool for the job, not always the most complex one. Simple, maintainable solutions often beat over-engineered ones.

I'll create a comprehensive guide for recognizing DSA patterns and choosing the right approach for real-world problems. This is essential for elite software engineering.I've created a comprehensive guide that elite software engineers can use to master DSA pattern recognition. Here's what makes this guide powerful:

## **Key Features:**

### **1. Keyword Recognition System**

The guide includes extensive tables mapping problem keywords to specific patterns. For example:

- "find duplicate" ‚Üí Hash Set
- "longest substring" ‚Üí Sliding Window
- "two sum" ‚Üí Two Pointers or Hash Map
- "subarray sum" ‚Üí Sliding Window
- "k largest" ‚Üí Heap pattern
- "shortest path" ‚Üí BFS/Dijkstra

### **2. Complete Implementations**

Every pattern includes production-ready code in **Python, Rust, and Go**, covering:

- Arrays/Strings
- Hash Maps/Sets
- Sliding Window (variable and fixed size)
- Two Pointers
- Fast/Slow Pointers
- Binary Search (including "binary search on answer space")
- Top K Elements (Heap and QuickSelect)
- Dynamic Programming (1D, 2D, optimization)
- Graph Traversal (BFS/DFS)

### **3. Decision Framework**

A flowchart-style decision tree helps you choose the right approach based on problem characteristics.
Before coding, the guide teaches you to ask:

- What are the keywords?
- What data structures are implied?
- What are the constraints? (This determines your time complexity target)
- Is the input sorted?
- What type of output is needed?
- Can I transform the problem?

### **4. Real-World Mappings**

It connects DSA to actual engineering:

- **Rate Limiter** ‚Üí Sliding Window
- **LRU Cache** ‚Üí HashMap + Doubly Linked List
- **Autocomplete** ‚Üí Trie
- **Load Balancer** ‚Üí Consistent Hashing

### **5. Complexity Shortcuts**

Quick rules like:

- n ‚â§ 20 ‚Üí Exponential algorithms OK
- n ‚â§ 10‚Å∂ ‚Üí Must be O(n) or O(n log n)
- "Contiguous" ‚Üí Think sliding window
- "Subsequence" ‚Üí Think DP

The guide emphasizes **pattern recognition over memorization** - teaching you to think like an elite engineer who can quickly identify the right approach for any problem.

## Elite Software Engineer's Guide: Keyword-to-DSA Pattern Recognition

## Table of Contents

1. [Core Pattern Recognition Framework](#core-pattern-recognition-framework)
2. [Keyword Mapping Matrix](#keyword-mapping-matrix)
3. [Domain-Specific Patterns](#domain-specific-patterns)
4. [Decision Framework](#decision-framework)
5. [Implementation Examples](#implementation-examples)

---

## Core Pattern Recognition Framework

### The 3-Step Analysis Method

**Step 1: IDENTIFY - Extract Signal Keywords**

- Data operation keywords (find, sort, count, path, optimize)
- Action verbs (find, count, maximize, minimize, track)
- Constraint words (unique, consecutive, overlapping, distinct)
- Structure hints (tree, graph, sequence, stream, interval)
- Performance requirements (real-time, concurrent, distributed)

**Step 2: CLASSIFY - Map to Pattern Family**

- What data structure fits? (array, linked list, tree, graph, hash)
- What operation dominates? (insert, delete, lookup, update)
- What's the access pattern? (sequential, random, range-based)
- What's the cardinality? (bounded, unbounded, streaming)
- What are the trade-offs? (time vs space, consistency vs availability)

**Step 3: OPTIMIZE - Select Best-Fit DSA**

- Analyze time/space complexity needs
- Consider your domain constraints
- Evaluate concurrency requirements
- Assess scalability needs
- Factor in operational complexity

---

## Keyword Mapping Matrix

### üîç Search & Retrieval Keywords

| Keywords | DSA Pattern | Use Case | Time Complexity |
|----------|-------------|----------|-----------------|
| **find, search, lookup, query** | Hash Map/Set | O(1) lookups needed | O(1) avg |
| **find in sorted, binary search** | Binary Search, B-Tree | Sorted data queries | O(log n) |
| **find nearest, closest** | KD-Tree, Ball Tree | Spatial/metric queries | O(log n) |
| **find top-k, k-largest** | Heap, Priority Queue | Bounded ranking | O(n log k) |
| **find pattern, substring** | KMP, Rabin-Karp, Aho-Corasick | String matching | O(n+m) |
| **find cycle, detect loop** | Floyd's Cycle, Union-Find | Graph cycles | O(n) |

### üìä Ordering & Ranking Keywords

| Keywords | DSA Pattern | Use Case | Time Complexity |
|----------|-------------|----------|-----------------|
| **sort, order, arrange** | QuickSort, MergeSort, Radix | General sorting | O(n log n) |
| **maintain sorted, dynamic sort** | Balanced BST, Heap | Online sorting | O(log n) insert |
| **rank, kth element** | QuickSelect, Median of Medians | Order statistics | O(n) avg |
| **priority, schedule, deadline** | Priority Queue, Heap | Task scheduling | O(log n) |
| **median, percentile** | Two Heaps, Order Statistics Tree | Streaming statistics | O(log n) |

### üî¢ Counting & Frequency Keywords

| Keywords | DSA Pattern | Use Case | Time Complexity |
|----------|-------------|----------|-----------------|
| **count, frequency, occurrence** | Hash Map, Counter | Frequency tracking | O(1) per op |
| **count unique, distinct** | Hash Set, Bloom Filter | Cardinality estimation | O(1) / approx |
| **count inversions** | Modified MergeSort, BIT | Array analysis | O(n log n) |
| **rolling count, sliding window** | Deque, Hash Map | Window statistics | O(1) amortized |

### üåê Graph & Network Keywords

| Keywords | DSA Pattern | Use Case | Time Complexity |
|----------|-------------|----------|-----------------|
| **path, route, navigate** | BFS, DFS, Dijkstra, A* | Path finding | O(V+E) to O(E log V) |
| **shortest path, minimum cost** | Dijkstra, Bellman-Ford, Floyd-Warshall | Network routing | O(E log V) to O(V¬≥) |
| **connectivity, reachability** | Union-Find, DFS/BFS | Network components | O(Œ±(n)) |
| **flow, capacity, bandwidth** | Max-Flow (Ford-Fulkerson, Dinic) | Network optimization | O(V¬≤E) |
| **dependency, topological** | Topological Sort, Kahn's Algorithm | Build systems, task ordering | O(V+E) |
| **spanning tree, minimum connection** | Kruskal's, Prim's | Network design | O(E log V) |
| **strongly connected** | Tarjan's, Kosaraju's | Network analysis | O(V+E) |

### üîÑ Stream & Sequence Keywords

| Keywords | DSA Pattern | Use Case | Time Complexity |
|----------|-------------|----------|-----------------|
| **stream, continuous, real-time** | Sliding Window, Reservoir Sampling | Online processing | O(1) per element |
| **consecutive, continuous, subarray** | Sliding Window, Kadane's | Contiguous sequences | O(n) |
| **subsequence, subset** | DP, Two Pointers | Non-contiguous patterns | O(n¬≤) or O(n) |
| **prefix, suffix** | Prefix Sum, Trie | Range queries | O(1) query |
| **interval, range, segment** | Segment Tree, Interval Tree | Range operations | O(log n) |

### üéØ Optimization Keywords

| Keywords | DSA Pattern | Use Case | Time Complexity |
|----------|-------------|----------|-----------------|
| **maximize, minimize, optimal** | Dynamic Programming, Greedy | Optimization problems | O(n¬≤) or O(n) |
| **knapsack, capacity, weight** | DP (0/1 or Unbounded) | Resource allocation | O(nW) |
| **partition, distribute, balance** | DP, Greedy, Load Balancing | Distribution problems | Varies |
| **schedule, assign, allocate** | Greedy, Hungarian Algorithm | Assignment problems | O(n¬≥) |

### üîí Security & Concurrency Keywords

| Keywords | DSA Pattern | Use Case | Notes |
|----------|-------------|----------|-------|
| **concurrent, parallel, thread-safe** | Lock-Free DS, RWLock, Mutex | Concurrent access | Use concurrent collections |
| **rate-limit, throttle, quota** | Token Bucket, Leaky Bucket | Rate limiting | O(1) check |
| **cache, memoize, expire** | LRU/LFU Cache, TTL Map | Caching strategies | O(1) ops |
| **access control, permission** | Trie, Hash Map, RBAC Tree | Authorization | O(log n) or O(1) |
| **audit, log, trace** | Append-Only Log, Ring Buffer | Monitoring | O(1) append |
| **isolation, sandbox, namespace** | Tree (hierarchical), Graph | Resource isolation | Domain-specific |

### üåç Distributed Systems Keywords

| Keywords | DSA Pattern | Use Case | CAP Trade-off |
|----------|-------------|----------|---------------|
| **distributed, replicated, consistent** | Consensus (Raft, Paxos), CRDT | Distributed coordination | CP or AP |
| **shard, partition, horizontal** | Consistent Hashing, Range Partitioning | Data distribution | Availability |
| **gossip, epidemic, eventual** | Gossip Protocol, Merkle Tree | Eventual consistency | AP |
| **quorum, majority, consensus** | Quorum-based algorithms | Strong consistency | CP |
| **vector clock, causal** | Vector Clocks, Lamport Timestamps | Ordering events | Causality |

---

## Domain-Specific Patterns

### ‚òÅÔ∏è Cloud & Infrastructure

#### Resource Management

- **Problem**: VM allocation with resource constraints
- **Keywords**: allocate, capacity, constraint, optimize
- **Pattern**: Bin Packing (First-Fit, Best-Fit) + Priority Queue
- **DSA**: Heap + Greedy Algorithm

#### Load Balancing

- **Problem**: Distribute requests across servers
- **Keywords**: balance, distribute, weight, health
- **Pattern**: Consistent Hashing + Weighted Round Robin
- **DSA**: Hash Ring + Priority Queue

#### Auto-scaling

- **Problem**: Scale resources based on metrics
- **Keywords**: threshold, monitor, scale, trend
- **Pattern**: Time Series Analysis + Sliding Window
- **DSA**: Circular Buffer + Moving Average

### üåê Networking

#### Packet Routing

- **Problem**: Route packets through network
- **Keywords**: route, path, latency, hop
- **Pattern**: Shortest Path with Constraints
- **DSA**: Dijkstra's with modifications, A*

#### Traffic Shaping

- **Problem**: Control bandwidth usage
- **Keywords**: rate, bandwidth, burst, limit
- **Pattern**: Token Bucket + Leaky Bucket
- **DSA**: Queue + Counter

#### DNS Resolution

- **Problem**: Resolve domain names efficiently
- **Keywords**: lookup, cache, TTL, hierarchy
- **Pattern**: Multi-level Cache + Trie
- **DSA**: LRU Cache + Trie

### üîê Security

#### Firewall Rules

- **Problem**: Match packets against rules efficiently
- **Keywords**: match, filter, rule, priority
- **Pattern**: Rule Matching + Priority Ordering
- **DSA**: Trie (for IP prefixes), Priority Queue

#### Intrusion Detection

- **Problem**: Detect anomalous patterns
- **Keywords**: pattern, anomaly, threshold, signature
- **Pattern**: Pattern Matching + Statistical Analysis
- **DSA**: Aho-Corasick, Bloom Filter, Sliding Window

#### Access Control

- **Problem**: Check permissions efficiently
- **Keywords**: permission, role, hierarchy, grant
- **Pattern**: RBAC Tree + Bitset
- **DSA**: Tree (for role hierarchy), Hash Map

### üì¶ Sandboxing & Virtualization

#### Resource Isolation

- **Problem**: Isolate resource access
- **Keywords**: isolate, namespace, limit, quota
- **Pattern**: Hierarchical Namespaces + Resource Tracking
- **DSA**: Tree + Hash Map

#### Process Management

- **Problem**: Schedule and track processes
- **Keywords**: schedule, priority, deadline, preempt
- **Pattern**: Multi-level Feedback Queue
- **DSA**: Priority Queue + Round Robin

---

## Decision Framework

### The CASER Framework

**C - Constraints**

- What are the size limits? (n < 10¬≥, 10‚Å∂, 10‚Åπ?)
- What are the time limits? (real-time, batch, interactive?)
- What are the space limits? (memory-constrained, distributed?)

**A - Access Pattern**

- Random or sequential?
- Read-heavy or write-heavy?
- Point queries or range queries?

**S - Scalability**

- Single-threaded or concurrent?
- Single-node or distributed?
- Static or dynamic data?

**E - Error Tolerance**

- Exact or approximate?
- Best-effort or guaranteed?
- Fault-tolerant requirements?

**R - Requirements**

- Latency requirements (p50, p95, p99)?
- Throughput requirements?
- Consistency requirements?

---

## Implementation Examples

### Example 1: Rate Limiter (Token Bucket)

**Keywords**: rate-limit, requests-per-second, burst, throttle
**Pattern**: Token Bucket Algorithm
**Use Case**: API rate limiting in cloud services

#### Rust Implementation

```rust
use std::time::{Duration, Instant};
use std::sync::{Arc, Mutex};

struct TokenBucket {
    capacity: u32,
    tokens: f64,
    rate: f64, // tokens per second
    last_refill: Instant,
}

impl TokenBucket {
    fn new(capacity: u32, rate: f64) -> Self {
        Self {
            capacity,
            tokens: capacity as f64,
            rate,
            last_refill: Instant::now(),
        }
    }

    fn refill(&mut self) {
        let now = Instant::now();
        let elapsed = now.duration_since(self.last_refill).as_secs_f64();
        
        self.tokens = (self.tokens + elapsed * self.rate).min(self.capacity as f64);
        self.last_refill = now;
    }

    fn try_consume(&mut self, tokens: u32) -> bool {
        self.refill();
        
        if self.tokens >= tokens as f64 {
            self.tokens -= tokens as f64;
            true
        } else {
            false
        }
    }
}

// Thread-safe version
type SafeTokenBucket = Arc<Mutex<TokenBucket>>;

fn create_rate_limiter(capacity: u32, rate: f64) -> SafeTokenBucket {
    Arc::new(Mutex::new(TokenBucket::new(capacity, rate)))
}

// Usage
fn handle_request(limiter: &SafeTokenBucket) -> Result<(), &'static str> {
    let mut bucket = limiter.lock().unwrap();
    if bucket.try_consume(1) {
        Ok(())
    } else {
        Err("Rate limit exceeded")
    }
}
```

#### Python Implementation

```python
import time
import threading
from typing import Optional

class TokenBucket:
    def __init__(self, capacity: int, rate: float):
        """
        capacity: maximum tokens
        rate: tokens per second
        """
        self.capacity = capacity
        self.tokens = float(capacity)
        self.rate = rate
        self.last_refill = time.time()
        self.lock = threading.Lock()
    
    def _refill(self):
        now = time.time()
        elapsed = now - self.last_refill
        
        self.tokens = min(
            self.capacity,
            self.tokens + elapsed * self.rate
        )
        self.last_refill = now
    
    def try_consume(self, tokens: int = 1) -> bool:
        with self.lock:
            self._refill()
            
            if self.tokens >= tokens:
                self.tokens -= tokens
                return True
            return False
    
    def wait_for_tokens(self, tokens: int = 1) -> None:
        """Blocking call that waits until tokens available"""
        while not self.try_consume(tokens):
            time.sleep(0.01)

# Usage for API rate limiting
class APIRateLimiter:
    def __init__(self, requests_per_second: int, burst: int):
        self.bucket = TokenBucket(burst, requests_per_second)
    
    def allow_request(self) -> bool:
        return self.bucket.try_consume(1)

# Example usage
limiter = APIRateLimiter(requests_per_second=100, burst=150)

def handle_api_request():
    if limiter.allow_request():
        # Process request
        return {"status": "success"}
    else:
        return {"status": "rate_limited", "error": "Too many requests"}
```

#### Go Implementation

```go
package main

import (
    "sync"
    "time"
)

type TokenBucket struct {
    capacity    float64
    tokens      float64
    rate        float64 // tokens per second
    lastRefill  time.Time
    mu          sync.Mutex
}

func NewTokenBucket(capacity int, rate float64) *TokenBucket {
    return &TokenBucket{
        capacity:   float64(capacity),
        tokens:     float64(capacity),
        rate:       rate,
        lastRefill: time.Now(),
    }
}

func (tb *TokenBucket) refill() {
    now := time.Now()
    elapsed := now.Sub(tb.lastRefill).Seconds()
    
    tb.tokens = min(tb.capacity, tb.tokens+elapsed*tb.rate)
    tb.lastRefill = now
}

func (tb *TokenBucket) TryConsume(tokens int) bool {
    tb.mu.Lock()
    defer tb.mu.Unlock()
    
    tb.refill()
    
    if tb.tokens >= float64(tokens) {
        tb.tokens -= float64(tokens)
        return true
    }
    return false
}

func min(a, b float64) float64 {
    if a < b {
        return a
    }
    return b
}

// Middleware example
func RateLimitMiddleware(limiter *TokenBucket) func(http.Handler) http.Handler {
    return func(next http.Handler) http.Handler {
        return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
            if !limiter.TryConsume(1) {
                http.Error(w, "Rate limit exceeded", http.StatusTooManyRequests)
                return
            }
            next.ServeHTTP(w, r)
        })
    }
}
```

---

### Example 2: LRU Cache with TTL (Cloud Caching)

**Keywords**: cache, expire, evict, most-recent, TTL
**Pattern**: LRU Cache + Time-based Expiration
**Use Case**: DNS caching, API response caching

#### Rust Implementation

```rust
use std::collections::{HashMap, VecDeque};
use std::time::{Duration, Instant};
use std::hash::Hash;

struct CacheEntry<V> {
    value: V,
    expires_at: Instant,
}

struct LRUCache<K, V> {
    capacity: usize,
    cache: HashMap<K, CacheEntry<V>>,
    order: VecDeque<K>,
    default_ttl: Duration,
}

impl<K: Eq + Hash + Clone, V: Clone> LRUCache<K, V> {
    fn new(capacity: usize, default_ttl: Duration) -> Self {
        Self {
            capacity,
            cache: HashMap::new(),
            order: VecDeque::new(),
            default_ttl,
        }
    }

    fn get(&mut self, key: &K) -> Option<V> {
        // Check if key exists and not expired
        if let Some(entry) = self.cache.get(key) {
            if Instant::now() < entry.expires_at {
                // Move to front (most recently used)
                self.order.retain(|k| k != key);
                self.order.push_front(key.clone());
                return Some(entry.value.clone());
            } else {
                // Expired, remove it
                self.cache.remove(key);
                self.order.retain(|k| k != key);
            }
        }
        None
    }

    fn put(&mut self, key: K, value: V) {
        self.put_with_ttl(key, value, self.default_ttl);
    }

    fn put_with_ttl(&mut self, key: K, value: V, ttl: Duration) {
        // Remove if already exists
        if self.cache.contains_key(&key) {
            self.order.retain(|k| k != &key);
        } else if self.cache.len() >= self.capacity {
            // Evict LRU item
            if let Some(lru_key) = self.order.pop_back() {
                self.cache.remove(&lru_key);
            }
        }

        let entry = CacheEntry {
            value,
            expires_at: Instant::now() + ttl,
        };

        self.cache.insert(key.clone(), entry);
        self.order.push_front(key);
    }

    fn cleanup_expired(&mut self) {
        let now = Instant::now();
        let expired: Vec<K> = self.cache
            .iter()
            .filter(|(_, entry)| now >= entry.expires_at)
            .map(|(k, _)| k.clone())
            .collect();

        for key in expired {
            self.cache.remove(&key);
            self.order.retain(|k| k != &key);
        }
    }
}

// Usage for DNS caching
fn dns_cache_example() {
    let mut cache = LRUCache::new(1000, Duration::from_secs(300));
    
    // Cache DNS response
    cache.put("example.com".to_string(), "93.184.216.34".to_string());
    
    // Retrieve
    if let Some(ip) = cache.get(&"example.com".to_string()) {
        println!("Cached IP: {}", ip);
    }
}
```

#### Python Implementation

```python
from collections import OrderedDict
from typing import Optional, Generic, TypeVar, Any
import time

K = TypeVar('K')
V = TypeVar('V')

class LRUCache(Generic[K, V]):
    def __init__(self, capacity: int, default_ttl: float = 300):
        """
        capacity: maximum number of items
        default_ttl: time-to-live in seconds
        """
        self.capacity = capacity
        self.default_ttl = default_ttl
        self.cache: OrderedDict[K, tuple[V, float]] = OrderedDict()
    
    def get(self, key: K) -> Optional[V]:
        if key not in self.cache:
            return None
        
        value, expires_at = self.cache[key]
        
        # Check expiration
        if time.time() > expires_at:
            del self.cache[key]
            return None
        
        # Move to end (most recently used)
        self.cache.move_to_end(key)
        return value
    
    def put(self, key: K, value: V, ttl: Optional[float] = None) -> None:
        ttl = ttl or self.default_ttl
        expires_at = time.time() + ttl
        
        if key in self.cache:
            # Update existing
            del self.cache[key]
        elif len(self.cache) >= self.capacity:
            # Evict LRU (first item)
            self.cache.popitem(last=False)
        
        self.cache[key] = (value, expires_at)
    
    def cleanup_expired(self) -> int:
        """Remove expired entries, return count removed"""
        now = time.time()
        expired = [k for k, (_, exp) in self.cache.items() if now > exp]
        for key in expired:
            del self.cache[key]
        return len(expired)

# Decorator for function result caching
def cached_with_ttl(cache: LRUCache, ttl: Optional[float] = None):
    def decorator(func):
        def wrapper(*args, **kwargs):
            # Create cache key from args
            key = (args, tuple(sorted(kwargs.items())))
            
            # Try cache first
            result = cache.get(key)
            if result is not None:
                return result
            
            # Compute and cache
            result = func(*args, **kwargs)
            cache.put(key, result, ttl)
            return result
        return wrapper
    return decorator

# Usage example: DNS resolver with caching
class DNSResolver:
    def __init__(self):
        self.cache = LRUCache[str, str](capacity=10000, default_ttl=300)
    
    def resolve(self, domain: str) -> Optional[str]:
        # Check cache
        cached = self.cache.get(domain)
        if cached:
            return cached
        
        # Actual DNS resolution (simulated)
        ip = self._actual_dns_lookup(domain)
        if ip:
            self.cache.put(domain, ip, ttl=300)
        return ip
    
    def _actual_dns_lookup(self, domain: str) -> Optional[str]:
        # Placeholder for actual DNS resolution
        import socket
        try:
            return socket.gethostbyname(domain)
        except:
            return None
```

#### Go Implementation

```go
package main

import (
    "container/list"
    "sync"
    "time"
)

type cacheEntry struct {
    key       interface{}
    value     interface{}
    expiresAt time.Time
}

type LRUCache struct {
    capacity   int
    cache      map[interface{}]*list.Element
    order      *list.List
    defaultTTL time.Duration
    mu         sync.RWMutex
}

func NewLRUCache(capacity int, defaultTTL time.Duration) *LRUCache {
    return &LRUCache{
        capacity:   capacity,
        cache:      make(map[interface{}]*list.Element),
        order:      list.New(),
        defaultTTL: defaultTTL,
    }
}

func (c *LRUCache) Get(key interface{}) (interface{}, bool) {
    c.mu.Lock()
    defer c.mu.Unlock()

    if elem, ok := c.cache[key]; ok {
        entry := elem.Value.(*cacheEntry)
        
        // Check expiration
        if time.Now().After(entry.expiresAt) {
            c.removeElement(elem)
            return nil, false
        }
        
        // Move to front (most recently used)
        c.order.MoveToFront(elem)
        return entry.value, true
    }
    
    return nil, false
}

func (c *LRUCache) Put(key, value interface{}) {
    c.PutWithTTL(key, value, c.defaultTTL)
}

func (c *LRUCache) PutWithTTL(key, value interface{}, ttl time.Duration) {
    c.mu.Lock()
    defer c.mu.Unlock()

    // Update existing
    if elem, ok := c.cache[key]; ok {
        c.order.MoveToFront(elem)
        entry := elem.Value.(*cacheEntry)
        entry.value = value
        entry.expiresAt = time.Now().Add(ttl)
        return
    }

    // Evict if at capacity
    if c.order.Len() >= c.capacity {
        c.removeOldest()
    }

    // Add new
    entry := &cacheEntry{
        key:       key,
        value:     value,
        expiresAt: time.Now().Add(ttl),
    }
    elem := c.order.PushFront(entry)
    c.cache[key] = elem
}

func (c *LRUCache) removeElement(elem *list.Element) {
    c.order.Remove(elem)
    entry := elem.Value.(*cacheEntry)
    delete(c.cache, entry.key)
}

func (c *LRUCache) removeOldest() {
    elem := c.order.Back()
    if elem != nil {
        c.removeElement(elem)
    }
}

func (c *LRUCache) CleanupExpired() int {
    c.mu.Lock()
    defer c.mu.Unlock()

    now := time.Now()
    count := 0
    
    for elem := c.order.Back(); elem != nil; {
        entry := elem.Value.(*cacheEntry)
        prev := elem.Prev()
        
        if now.After(entry.expiresAt) {
            c.removeElement(elem)
            count++
        }
        
        elem = prev
    }
    
    return count
}

// Usage example: DNS resolver
type DNSResolver struct {
    cache *LRUCache
}

func NewDNSResolver() *DNSResolver {
    return &DNSResolver{
        cache: NewLRUCache(10000, 5*time.Minute),
    }
}

func (r *DNSResolver) Resolve(domain string) (string, bool) {
    // Check cache
    if ip, ok := r.cache.Get(domain); ok {
        return ip.(string), true
    }
    
    // Actual DNS resolution
    ip := r.actualDNSLookup(domain)
    if ip != "" {
        r.cache.Put(domain, ip)
        return ip, true
    }
    
    return "", false
}

func (r *DNSResolver) actualDNSLookup(domain string) string {
    // Placeholder for actual DNS resolution
    return ""
}
```

---

### Example 3: Consistent Hashing (Load Balancing)

**Keywords**: distribute, balance, scale, partition, shard
**Pattern**: Consistent Hashing with Virtual Nodes
**Use Case**: Load balancing, distributed caching, data partitioning

#### Rust Implementation

```rust
use std::collections::{BTreeMap, HashSet};
use std::hash::{Hash, Hasher};
use std::collections::hash_map::DefaultHasher;

struct ConsistentHash {
    ring: BTreeMap<u64, String>,
    virtual_nodes: usize,
    nodes: HashSet<String>,
}

impl ConsistentHash {
    fn new(virtual_nodes: usize) -> Self {
        Self {
            ring: BTreeMap::new(),
            virtual_nodes,
            nodes: HashSet::new(),
        }
    }

    fn hash_key(&self, key: &str) -> u64 {
        let mut hasher = DefaultHasher::new();
        key.hash(&mut hasher);
        hasher.finish()
    }

    fn add_node(&mut self, node: String) {
        if self.nodes.insert(node.clone()) {
            // Add virtual nodes
            for i in 0..self.virtual_nodes {
                let virtual_key = format!("{}:{}", node, i);
                let hash = self.hash_key(&virtual_key);
                self.ring.insert(hash, node.clone());
            }
        }
    }

    fn remove_node(&mut self, node: &str) {
        if self.nodes.remove(node) {
            // Remove virtual nodes
            for i in 0..self.virtual_nodes {
                let virtual_key = format!("{}:{}", node, i);
                let hash = self.hash_key(&virtual_key);
                self.ring.remove(&hash);
            }
        }
    }

    fn get_node(&self, key: &str) -> Option<&String> {
        if self.ring.is_empty() {
            return None;
        }

        let hash = self.hash_key(key);
        
        // Find first node >= hash
        for (_, node) in self.ring.range(hash..) {
            return Some(node);
        }
        
        // Wrap around to first node
        self.ring.values().next()
    }

    fn get_n_nodes(&self, key: &str, n: usize) -> Vec<String> {
        if self.ring.is_empty() {
            return Vec::new();
        }

        let hash = self.hash_key(key);
        let mut result = Vec::new();
        let mut seen = HashSet::new();

        // Collect from hash position
        for (_, node) in self.ring.range(hash..) {
            if seen.insert(node.clone()) {
                result.push(node.clone());
                if result.len() >= n {
                    return result;
                }
            }
        }

        // Wrap around
        for (_, node) in &self.ring {
            if seen.insert(node.clone()) {
                result.push(node.clone());
                if result.len() >= n {
                    return result;
                }
            }
        }

        result
    }
}

// Usage for load balancing
fn load_balancer_example() {
    let mut lb = ConsistentHash::new(150); // 150 virtual nodes per server
    
    // Add servers
    lb.add_node("server1:8080".to_string());
    lb.add_node("server2:8080".to_string());
    lb.add_node("server3:8080".to_string());
    
    // Route request
    let user_id = "user12345";
    if let Some(server) = lb.get_node(user_id) {
        println!("Route {} to {}", user_id, server);
    }
    
    // For replicated data, get multiple nodes
    let replicas = lb.get_n_nodes(user_id, 3);
    println!("Replicate to: {:?}", replicas);
}
```

#### Python Implementation

```python
from bisect import bisect_right
from typing import List, Optional, Set
import hashlib

class ConsistentHash:
    def __init__(self, virtual_nodes: int = 150):
        """
        virtual_nodes: number of virtual nodes per physical node
        """
        self.virtual_nodes = virtual_nodes
        self.ring: List[int] = []
        self.ring_map: dict[int, str] = {}
        self.nodes: Set[str] = set()
    
    def _hash(self, key: str) -> int:
        """Hash function returning 32-bit integer"""
        return int(hashlib.md5(key.encode()).hexdigest(), 16)
    
    def add_node(self, node: str) -> None:
        """Add a physical node to the ring"""
        if node in self.nodes:
            return
        
        self.nodes.add(node)
        
        # Add virtual nodes
        for i in range(self.virtual_nodes):
            virtual_key = f"{node}:{i}"
            hash_value = self._hash(virtual_key)
            
            self.ring.append(hash_value)
            self.ring_map[hash_value] = node
        
        # Keep ring sorted
        self.ring.sort()
    
    def remove_node(self, node: str) -> None:
        """Remove a physical node from the ring"""
        if node not in self.nodes:
            return
        
        self.nodes.remove(node)
        
        # Remove virtual nodes
        for i in range(self.virtual_nodes):
            virtual_key = f"{node}:{i}"
            hash_value = self._hash(virtual_key)
            
            if hash_value in self.ring_map:
                del self.ring_map[hash_value]
                self.ring.remove(hash_value)
    
    def get_node(self, key: str) -> Optional[str]:
        """Get the node responsible for this key"""
        if not self.ring:
            return None
        
        hash_value = self._hash(key)
        
        # Find first node >= hash_value
        idx = bisect_right(self.ring, hash_value)
        
        # Wrap around if necessary
        if idx == len(self.ring):
            idx = 0
        
        return self.ring_map[self.ring[idx]]
    
    def get_n_nodes(self, key: str, n: int) -> List[str]:
        """Get n nodes for replication"""
        if not self.ring:
            return []
        
        hash_value = self._hash(key)
        idx = bisect_right(self.ring, hash_value)
        
        result = []
        seen = set()
        
        # Collect n unique physical nodes
        for i in range(len(self.ring)):
            pos = (idx + i) % len(self.ring)
            node = self.ring_map[self.ring[pos]]
            
            if node not in seen:
                seen.add(node)
                result.append(node)
                
                if len(result) >= n:
                    break
        
        return result

# Usage: Distributed cache with consistent hashing
class DistributedCache:
    def __init__(self):
        self.hasher = ConsistentHash(virtual_nodes=150)
        self.cache_nodes = {}  # node_id -> cache_instance
    
    def add_cache_node(self, node_id: str, cache_instance):
        self.hasher.add_node(node_id)
        self.cache_nodes[node_id] = cache_instance
    
    def get(self, key: str):
        node = self.hasher.get_node(key)
        if node and node in self.cache_nodes:
            return self.cache_nodes[node].get(key)
        return None
    
    def set(self, key: str, value, replicas: int = 2):
        nodes = self.hasher.get_n_nodes(key, replicas)
        for node in nodes:
            if node in self.cache_nodes:
                self.cache_nodes[node].set(key, value)

# Load balancer example
class LoadBalancer:
    def __init__(self):
        self.hasher = ConsistentHash(virtual_nodes=150)
    
    def add_server(self, server: str):
        self.hasher.add_node(server)
    
    def remove_server(self, server: str):
        self.hasher.remove_node(server)
    
    def get_server(self, request_id: str) -> Optional[str]:
        """Route request to server based on request ID"""
        return self.hasher.get_node(request_id)

# Example usage
lb = LoadBalancer()
lb.add_server("server1:8080")
lb.add_server("server2:8080")
lb.add_server("server3:8080")

# Route requests
for i in range(10):
    request_id = f"request-{i}"
    server = lb.get_server(request_id)
    print(f"Route {request_id} -> {server}")
```

#### Go Implementation

```go
package main

import (
    "crypto/md5"
    "encoding/binary"
    "fmt"
    "sort"
    "sync"
)

type ConsistentHash struct {
    ring         []uint32
    ringMap      map[uint32]string
    nodes        map[string]bool
    virtualNodes int
    mu           sync.RWMutex
}

func NewConsistentHash(virtualNodes int) *ConsistentHash {
    return &ConsistentHash{
        ring:         make([]uint32, 0),
        ringMap:      make(map[uint32]string),
        nodes:        make(map[string]bool),
        virtualNodes: virtualNodes,
    }
}

func (ch *ConsistentHash) hash(key string) uint32 {
    hash := md5.Sum([]byte(key))
    return binary.BigEndian.Uint32(hash[:4])
}

func (ch *ConsistentHash) AddNode(node string) {
    ch.mu.Lock()
    defer ch.mu.Unlock()

    if ch.nodes[node] {
        return
    }

    ch.nodes[node] = true

    // Add virtual nodes
    for i := 0; i < ch.virtualNodes; i++ {
        virtualKey := fmt.Sprintf("%s:%d", node, i)
        hash := ch.hash(virtualKey)
        
        ch.ring = append(ch.ring, hash)
        ch.ringMap[hash] = node
    }

    sort.Slice(ch.ring, func(i, j int) bool {
        return ch.ring[i] < ch.ring[j]
    })
}

func (ch *ConsistentHash) RemoveNode(node string) {
    ch.mu.Lock()
    defer ch.mu.Unlock()

    if !ch.nodes[node] {
        return
    }

    delete(ch.nodes, node)

    // Remove virtual nodes
    newRing := make([]uint32, 0)
    for i := 0; i < ch.virtualNodes; i++ {
        virtualKey := fmt.Sprintf("%s:%d", node, i)
        hash := ch.hash(virtualKey)
        delete(ch.ringMap, hash)
    }

    for _, h := range ch.ring {
        if _, ok := ch.ringMap[h]; ok {
            newRing = append(newRing, h)
        }
    }

    ch.ring = newRing
}

func (ch *ConsistentHash) GetNode(key string) string {
    ch.mu.RLock()
    defer ch.mu.RUnlock()

    if len(ch.ring) == 0 {
        return ""
    }

    hash := ch.hash(key)

    // Binary search for first node >= hash
    idx := sort.Search(len(ch.ring), func(i int) bool {
        return ch.ring[i] >= hash
    })

    // Wrap around if necessary
    if idx == len(ch.ring) {
        idx = 0
    }

    return ch.ringMap[ch.ring[idx]]
}

func (ch *ConsistentHash) GetNNodes(key string, n int) []string {
    ch.mu.RLock()
    defer ch.mu.RUnlock()

    if len(ch.ring) == 0 {
        return nil
    }

    hash := ch.hash(key)
    idx := sort.Search(len(ch.ring), func(i int) bool {
        return ch.ring[i] >= hash
    })

    result := make([]string, 0, n)
    seen := make(map[string]bool)

    for i := 0; i < len(ch.ring) && len(result) < n; i++ {
        pos := (idx + i) % len(ch.ring)
        node := ch.ringMap[ch.ring[pos]]

        if !seen[node] {
            seen[node] = true
            result = append(result, node)
        }
    }

    return result
}

// Load balancer implementation
type LoadBalancer struct {
    hasher *ConsistentHash
}

func NewLoadBalancer() *LoadBalancer {
    return &LoadBalancer{
        hasher: NewConsistentHash(150),
    }
}

func (lb *LoadBalancer) AddServer(server string) {
    lb.hasher.AddNode(server)
}

func (lb *LoadBalancer) RemoveServer(server string) {
    lb.hasher.RemoveNode(server)
}

func (lb *LoadBalancer) GetServer(requestID string) string {
    return lb.hasher.GetNode(requestID)
}

// Example usage
func main() {
    lb := NewLoadBalancer()
    
    // Add servers
    lb.AddServer("server1:8080")
    lb.AddServer("server2:8080")
    lb.AddServer("server3:8080")
    
    // Route requests
    for i := 0; i < 10; i++ {
        requestID := fmt.Sprintf("request-%d", i)
        server := lb.GetServer(requestID)
        fmt.Printf("Route %s -> %s\n", requestID, server)
    }
}
```

---

## Quick Reference Cheat Sheet

### Pattern Recognition Shortcuts

```
FIND + SORTED              ‚Üí Binary Search
FIND + UNSORTED            ‚Üí Hash Map
FIND + TOP-K               ‚Üí Heap
FIND + RANGE               ‚Üí Segment Tree / BIT

COUNT + FREQUENCY          ‚Üí Hash Map / Counter
COUNT + UNIQUE             ‚Üí Hash Set / Bloom Filter
COUNT + SLIDING            ‚Üí Deque + Hash Map

PATH + UNWEIGHTED          ‚Üí BFS
PATH + WEIGHTED            ‚Üí Dijkstra / A*
PATH + NEGATIVE WEIGHTS    ‚Üí Bellman-Ford
PATH + ALL PAIRS           ‚Üí Floyd-Warshall

OPTIMIZE + SUBSTRUCTURE    ‚Üí Dynamic Programming
OPTIMIZE + GREEDY CHOICE   ‚Üí Greedy Algorithm
OPTIMIZE + CONSTRAINTS     ‚Üí Backtracking / Branch & Bound

STREAM + FIXED WINDOW      ‚Üí Circular Buffer
STREAM + SLIDING WINDOW    ‚Üí Deque
STREAM + TOP-K             ‚Üí Heap
STREAM + UNIQUE            ‚Üí Sliding Hash Set

CONCURRENT + READ-HEAVY    ‚Üí RWLock / Lock-Free
CONCURRENT + WRITE-HEAVY   ‚Üí Sharded Locks
CONCURRENT + QUEUE         ‚Üí Lock-Free Queue

DISTRIBUTED + PARTITION    ‚Üí Consistent Hashing
DISTRIBUTED + CONSENSUS    ‚Üí Raft / Paxos
DISTRIBUTED + CACHE        ‚Üí DHT / Consistent Hash
```

### Complexity Quick Guide

| Operation | Array | Linked List | BST (balanced) | Hash Map | Heap |
|-----------|-------|-------------|----------------|----------|------|
| Search    | O(n)  | O(n)        | O(log n)       | O(1)     | O(n) |
| Insert    | O(n)  | O(1)        | O(log n)       | O(1)     | O(log n) |
| Delete    | O(n)  | O(1)*       | O(log n)       | O(1)     | O(log n) |
| Min/Max   | O(n)  | O(n)        | O(log n)       | O(n)     | O(1) |

*Assuming you have the node reference

---

## Advanced Pattern Recognition

### Composite Patterns

Many real-world problems require combining multiple patterns:

1. **Leaderboard System** = Heap + Hash Map
   - Heap for top-K rankings
   - Hash Map for O(1) user lookup
   - Update requires both structures

2. **Time-Series Database** = Segment Tree + LSM Tree
   - Segment Tree for range queries
   - LSM Tree for write-heavy workload
   - Compression for historical data

3. **API Gateway** = Trie + Rate Limiter + Load Balancer
   - Trie for route matching
   - Token Bucket for rate limiting
   - Consistent Hash for load balancing

4. **Distributed Lock** = Consensus + TTL + Fencing Token
   - Raft/Paxos for agreement
   - TTL for automatic release
   - Fencing token for safety

---

## Final Checklist for Elite Engineers

Before implementing, ask yourself:

‚úÖ **Requirements Analysis**

- [ ] What is the exact problem statement?
- [ ] What are the input and output formats?
- [ ] What are the constraints (time, space, scale)?
- [ ] What are the edge cases?
- [ ] What are the performance requirements (latency, throughput)?

‚úÖ **Pattern Recognition**

- [ ] What keywords appear in the problem?
- [ ] Which pattern family does this belong to?
- [ ] Are there multiple patterns to combine?
- [ ] What are the trade-offs between options?

‚úÖ **Implementation Strategy**

- [ ] What's the simplest solution that works?
- [ ] How can I optimize it?
- [ ] How do I handle concurrency?
- [ ] How do I handle failures?

‚úÖ **Validation**

- [ ] Does it handle edge cases?
- [ ] Does it meet performance requirements?
- [ ] Is it maintainable and testable?
- [ ] Does it scale to the required load?

‚úÖ **Production Readiness**

- [ ] Monitoring and observability?
- [ ] Error handling and recovery?
- [ ] Resource cleanup and leak prevention?
- [ ] Documentation and runbooks?

---

## Resources for Continuous Learning

1. **Practice Platforms**
   - LeetCode (by pattern tags)
   - HackerRank (by domain)
   - System Design Primer (GitHub)

2. **Books**
   - "Designing Data-Intensive Applications" - Martin Kleppmann
   - "Introduction to Algorithms" - CLRS
   - "The Algorithm Design Manual" - Steven Skiena

3. **Real-world Systems**
   - Study open-source projects (Redis, Kafka, Kubernetes)
   - Read engineering blogs (Netflix, Uber, Facebook)
   - Analyze production incidents and post-mortems

Remember: **Pattern recognition is a skill built through practice.** Start with problems, identify patterns, implement solutions, and iterate. Over time, you'll develop intuition for mapping keywords to optimal DSA choices.

I'll create a comprehensive guide for recognizing problem patterns and selecting the right data structures and algorithms. This is essential for elite software engineering, especially in your domains.I've created a comprehensive guide for you! This is designed specifically for elite engineers working in cloud, networking, security, and infrastructure.

## Key Highlights:

**üéØ Pattern Recognition Framework**

- **IDENTIFY**: Extract keywords from problem statements
- **CLASSIFY**: Map to DSA pattern families
- **OPTIMIZE**: Select best-fit based on constraints

**üìã Extensive Keyword Matrices** covering:

- Search & Retrieval (hash maps, binary search, spatial queries)
- Graph & Network problems (routing, flow, connectivity)
- Concurrency & Security (rate limiting, caching, access control)
- Distributed Systems (consensus, partitioning, consistency)

**üèóÔ∏è Domain-Specific Patterns** for:

- Cloud resource management (bin packing, load balancing)
- Network operations (packet routing, traffic shaping, DNS)
- Security systems (firewall rules, intrusion detection, RBAC)
- Virtualization (resource isolation, process scheduling)

**üíª Three Complete Production-Ready Examples**:

1. **Rate Limiter** (Token Bucket) - for API throttling
2. **LRU Cache with TTL** - for distributed caching
3. **Consistent Hashing** - for load balancing & sharding

Each with full implementations in **Rust, Python, and Go**, including thread-safety and error handling.

**üß† The CASER Decision Framework**:

- **C**onstraints (size, time, space limits)
- **A**ccess Pattern (random, sequential, range)
- **S**calability (concurrent, distributed, dynamic)
- **E**rror Tolerance (exact, approximate, fault-tolerant)
- **R**equirements (latency, throughput, consistency)

The guide includes quick-reference cheat sheets and a final checklist to ensure you always choose the optimal approach. Use it as your go-to reference when architecting systems or solving complex problems!

### üß≠ 1. The Meta-Framework: How to Choose

Think of each technique as a **weapon in your arsenal**. The choice depends on:

| Problem Signal | Likely Technique | Mental Model |
|----------------|------------------|--------------|
| **Overlapping subproblems, optimal substructure** | Dynamic Programming (DP) | Crystal ball: reuse past solutions to predict future. |
| **Exploring all possibilities, constraints, undoing choices** | Backtracking | Maze explorer: try a path, backtrack if dead end. |
| **Divide into smaller identical subproblems** | Recursion | Fractal: self-similar structure. |
| **Need O(1) lookups, frequency counts, deduplication** | Hash Table | Magic ledger: instant membership check. |
| **Contiguous subarray / substring optimization** | Sliding Window | Telescope: adjust lens to capture moving range. |
| **Sequential data, fixed size** | Array | Straight road: indexed, cache-friendly. |
| **Grid/2D structure, adjacency** | Matrix / Graph traversal | Chessboard: moves constrained by neighbors. |
| **Locally optimal ‚Üí globally optimal** | Greedy | Always grab the shiniest coin first. |
| **Combination of above** | Hybrid | Forge multiple weapons into one. |

---

### üß† 2. Memory Model & Call Semantics

- **Recursion** ‚Üí stack frames grow; risk of stack overflow. Rust requires explicit `Box`/`Rc` for heap recursion.  
- **DP** ‚Üí can be top-down (recursion + memoization) or bottom-up (iterative, heap arrays).  
- **Backtracking** ‚Üí stack-heavy; often exponential.  
- **Hash Table** ‚Üí heap allocations, pointer chasing.  
- **Sliding Window** ‚Üí stack variables for indices, heap for data.  
- **Greedy** ‚Üí usually O(1) memory, stack-local.  
- **Matrix** ‚Üí heap-allocated 2D arrays; cache locality matters.  

---

### ‚öôÔ∏è 3. Language-Specific Idioms

### **Rust**

```rust
// Recursion
fn factorial(n: u64) -> u64 {
    if n <= 1 { 1 } else { n * factorial(n - 1) }
}

// DP (bottom-up)
fn fib(n: usize) -> u64 {
    let mut dp = vec![0; n+1];
    dp[0] = 0; dp[1] = 1;
    for i in 2..=n {
        dp[i] = dp[i-1] + dp[i-2];
    }
    dp[n]
}

// Hash table
use std::collections::HashMap;
let mut freq = HashMap::new();
for x in vec![1,2,2,3] {
    *freq.entry(x).or_insert(0) += 1;
}
```

---

### **Python**

```python
# Recursion
def factorial(n):
    return 1 if n <= 1 else n * factorial(n-1)

# DP (memoization)
from functools import lru_cache
@lru_cache(None)
def fib(n):
    if n < 2: return n
    return fib(n-1) + fib(n-2)

# Sliding window
def max_subarray_sum(nums, k):
    window_sum = sum(nums[:k])
    max_sum = window_sum
    for i in range(k, len(nums)):
        window_sum += nums[i] - nums[i-k]
        max_sum = max(max_sum, window_sum)
    return max_sum
```

---

### **Go**

```go
// Recursion
func factorial(n int) int {
    if n <= 1 { return 1 }
    return n * factorial(n-1)
}

// DP
func fib(n int) int {
    dp := make([]int, n+1)
    dp[0], dp[1] = 0, 1
    for i := 2; i <= n; i++ {
        dp[i] = dp[i-1] + dp[i-2]
    }
    return dp[n]
}

// Hash map
freq := make(map[int]int)
for _, x := range []int{1,2,2,3} {
    freq[x]++
}
```

---

### üèÜ 4. Elite Heuristics

- **Ask the right meta-question**:  
  - *Do I need all possibilities?* ‚Üí Backtracking.  
  - *Do I need optimal reuse?* ‚Üí DP.  
  - *Do I need fast lookup?* ‚Üí Hash table.  
  - *Do I need contiguous optimization?* ‚Üí Sliding window.  
  - *Do I need local greedy choices?* ‚Üí Greedy.  
  - *Do I need to traverse a grid/graph?* ‚Üí Matrix/Graph BFS/DFS.  

- **Hybridization is common**:  
  - DP + Hashing (memoization).  
  - Backtracking + Pruning (branch & bound).  
  - Sliding window + Hash table (longest substring without repeats).  

- **Performance awareness**:  
  - Rust: prefer iterators and explicit ownership.  
  - Python: leverage built-ins (`set`, `dict`, `any`, `all`).  
  - Go: exploit slices and maps, avoid recursion for deep calls.  

- **Clarity > Cleverness**:  
  - Write the condition in domain terms (`is_valid_move`, `is_palindrome`) instead of raw checks.  

---

### üåå Fantasy Anchor

Imagine you‚Äôre a **celestial strategist**:

- **Recursion** ‚Üí summoning fractal spirits.  
- **DP** ‚Üí inscribing runes in a spellbook to reuse power.  
- **Backtracking** ‚Üí wandering a labyrinth with chalk marks.  
- **Hash table** ‚Üí a cosmic ledger of instant truths.  
- **Sliding window** ‚Üí a telescope scanning the heavens.  
- **Greedy** ‚Üí a dragon hoarding the brightest gems.  
- **Matrix** ‚Üí a star map grid, each node a constellation.  

---

‚úÖ **Summary for elite engineers**:

- Start with **problem signals** (overlap, optimality, exploration, lookup, contiguity).  
- Map to **technique** (DP, recursion, backtracking, hash, sliding window, greedy, matrix).  
- Use **language idioms** for clarity and performance.  
- Combine techniques when signals overlap.  
- Always optimize for **clarity, correctness, and maintainability** before micro-optimizing.  

---

Would you like me to now craft a **decision tree diagram** (problem signals ‚Üí technique choice) so you can visually anchor this guide as a one-glance reference?

