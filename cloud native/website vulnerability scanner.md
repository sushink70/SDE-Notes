# Website Vulnerability Scanner - Comprehensive Technical Deep-Dive

## Executive Summary (4-8 lines)

Website vulnerability scanners are automated tools that probe web applications for security flaws by enumerating attack surfaces, injecting payloads, analyzing responses, and correlating behaviors against known vulnerability signatures. They operate across L7 (HTTP/HTTPS), parsing HTML/JS/CSS, executing dynamic crawlers, fingerprinting tech stacks, fuzzing inputs, and detecting patterns like SQLi, XSS, SSRF, auth bypasses, and misconfigurations. Production scanners combine active probing (send malicious payloads), passive analysis (traffic inspection), and static code analysis with parallel execution, rate-limiting, session management, and evasion techniques. Core challenges include false positives, state management, authentication handling, modern SPA/API scanning, WAF evasion, and maintaining vulnerability signature databases. Building one requires deep HTTP protocol knowledge, regex engines, parsers, concurrent workers, fingerprinting databases, and ethical/legal boundaries.

---

## I. Core Concepts & Architecture

### A. Vulnerability Scanner Taxonomy

```
┌─────────────────────────────────────────────────────────────┐
│                  Vulnerability Scanner Types                 │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐      │
│  │   ACTIVE     │  │   PASSIVE    │  │   HYBRID     │      │
│  │   SCANNING   │  │   SCANNING   │  │   SCANNING   │      │
│  └──────┬───────┘  └──────┬───────┘  └──────┬───────┘      │
│         │                  │                  │              │
│    Sends payloads    Monitors traffic    Combines both      │
│    Probes endpoints  No modification    Active+Passive      │
│    Fuzzes inputs     Learns patterns    Context-aware       │
│         │                  │                  │              │
│  ┌──────▼──────────────────▼──────────────────▼───────┐    │
│  │                Scanner Engine Core                  │    │
│  │  ┌──────────┐ ┌──────────┐ ┌──────────┐           │    │
│  │  │ Crawler  │ │ Parser   │ │ Analyzer │           │    │
│  │  └────┬─────┘ └────┬─────┘ └────┬─────┘           │    │
│  │       │            │            │                  │    │
│  │  ┌────▼────────────▼────────────▼─────┐           │    │
│  │  │      Attack Surface Mapper         │           │    │
│  │  └────┬──────────────────────────┬────┘           │    │
│  │       │                          │                 │    │
│  │  ┌────▼─────┐            ┌───────▼──────┐         │    │
│  │  │ Payload  │            │ Fingerprint  │         │    │
│  │  │ Engine   │            │ Engine       │         │    │
│  │  └────┬─────┘            └───────┬──────┘         │    │
│  │       │                          │                 │    │
│  │  ┌────▼──────────────────────────▼────┐           │    │
│  │  │      Vulnerability Detector        │           │    │
│  │  └────┬───────────────────────────────┘           │    │
│  │       │                                            │    │
│  │  ┌────▼─────────────────────────┐                 │    │
│  │  │   Report & Evidence Storage  │                 │    │
│  │  └──────────────────────────────┘                 │    │
│  └─────────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────────┘
```

### B. Under-the-Hood: HTTP Scanner Architecture

```
┌───────────────────────────────────────────────────────────────┐
│                    Scanner Architecture                        │
└───────────────────────────────────────────────────────────────┘

┌─────────────┐         ┌──────────────────────────────┐
│   Target    │         │      Input Handler           │
│   Config    │────────▶│  - URL Parsing               │
│             │         │  - Scope Definition          │
│  - URLs     │         │  - Auth Tokens               │
│  - Auth     │         │  - Rate Limits               │
│  - Scope    │         └──────────┬───────────────────┘
│  - Plugins  │                    │
└─────────────┘                    ▼
                          ┌────────────────────┐
                          │   Crawler Engine   │
                          ├────────────────────┤
                          │ • Link Discovery   │
                          │ • Form Detection   │
         ┌────────────────│ • JS Execution     │
         │                │ • DOM Parsing      │
         │                │ • Sitemap/Robots   │
         │                └────┬───────────────┘
         │                     │
         │                     ▼
         │            ┌─────────────────────┐
         │            │  Request Queue      │◀──┐
         │            │  (Priority Queue)   │   │
         │            └────┬────────────────┘   │
         │                 │                    │
         │                 ▼                    │
         │     ┌────────────────────────┐       │
         │     │  Worker Pool Manager   │       │
         │     │  (Concurrent Workers)  │       │
         │     └────┬───────────────────┘       │
         │          │                           │
         │          ▼                           │
         │   ┌──────────────┐                  │
         │   │   Worker 1   │──┐               │
         │   │   Worker 2   │  │               │
         │   │   Worker N   │  │               │
         │   └──────┬───────┘  │               │
         │          │          │               │
         │          ▼          │               │
         │   ┌─────────────────▼──────┐        │
         └──▶│  HTTP Client Layer     │        │
             │  ┌──────────────────┐  │        │
             │  │ TLS Handler      │  │        │
             │  │ Proxy Support    │  │        │
             │  │ Cookie Manager   │  │        │
             │  │ Header Injection │  │        │
             │  │ Retry Logic      │  │        │
             │  └──────────────────┘  │        │
             └────────┬────────────────┘        │
                      │                         │
                      ▼                         │
          ┌───────────────────────┐             │
          │  Response Processor   │             │
          ├───────────────────────┤             │
          │ • Status Code Check   │             │
          │ • Header Analysis     │             │
          │ • Body Parsing        │             │
          │ • Diff Analysis       │             │
          │ • Signature Matching  │             │
          └────────┬──────────────┘             │
                   │                            │
                   ▼                            │
        ┌──────────────────────┐                │
        │  Vulnerability DB    │                │
        │  ┌────────────────┐  │                │
        │  │ SQLi Patterns  │  │                │
        │  │ XSS Vectors    │  │                │
        │  │ SSRF Payloads  │  │                │
        │  │ Path Traversal │  │                │
        │  │ XXE Signatures │  │                │
        │  │ Auth Bypasses  │  │                │
        │  └────────────────┘  │                │
        └────────┬─────────────┘                │
                 │                              │
                 ▼                              │
      ┌──────────────────────┐                  │
      │  Detection Engine    │                  │
      ├──────────────────────┤                  │
      │ • Pattern Matching   │                  │
      │ • Heuristic Analysis │                  │
      │ • Blind Detection    │                  │
      │ • Time-based Tests   │                  │
      │ • OOB Channels       │──────────────────┘
      │ • ML-based Detection │  (Feedback Loop)
      └────────┬─────────────┘
               │
               ▼
    ┌──────────────────────┐
    │  Evidence Collector  │
    ├──────────────────────┤
    │ • Request/Response   │
    │ • Proof of Concept   │
    │ • Screenshot         │
    │ • Payload Used       │
    └────────┬─────────────┘
             │
             ▼
    ┌──────────────────────┐
    │  Report Generator    │
    ├──────────────────────┤
    │ • JSON/XML/HTML      │
    │ • CVSS Scoring       │
    │ • Remediation Steps  │
    │ • Risk Ranking       │
    └──────────────────────┘
```

---

## II. Core Components Deep-Dive

### A. HTTP Client Layer Implementation (Go)

```go
// pkg/httpclient/client.go
package httpclient

import (
    "context"
    "crypto/tls"
    "fmt"
    "io"
    "net"
    "net/http"
    "net/http/cookiejar"
    "net/url"
    "sync"
    "time"
    
    "golang.org/x/net/publicsuffix"
)

// ScannerHTTPClient wraps http.Client with scanner-specific features
type ScannerHTTPClient struct {
    client      *http.Client
    transport   *http.Transport
    jar         http.CookieJar
    rateLimiter *RateLimiter
    proxy       *url.URL
    mu          sync.RWMutex
    
    // Tracking
    requestCount  uint64
    bytesReceived uint64
    
    // Configuration
    cfg ClientConfig
}

type ClientConfig struct {
    Timeout             time.Duration
    MaxIdleConns        int
    MaxConnsPerHost     int
    IdleConnTimeout     time.Duration
    TLSHandshakeTimeout time.Duration
    DisableKeepAlives   bool
    DisableCompression  bool
    
    // TLS Configuration
    InsecureSkipVerify bool
    TLSMinVersion      uint16
    TLSMaxVersion      uint16
    
    // Proxy
    ProxyURL string
    
    // Rate Limiting
    RequestsPerSecond int
    BurstSize         int
    
    // Retry
    MaxRetries     int
    RetryWaitMin   time.Duration
    RetryWaitMax   time.Duration
    
    // Custom Headers
    UserAgent string
    Headers   map[string]string
}

func NewScannerHTTPClient(cfg ClientConfig) (*ScannerHTTPClient, error) {
    // Create cookie jar with public suffix list
    jar, err := cookiejar.New(&cookiejar.Options{
        PublicSuffixList: publicsuffix.List,
    })
    if err != nil {
        return nil, fmt.Errorf("failed to create cookie jar: %w", err)
    }
    
    // Configure TLS
    tlsConfig := &tls.Config{
        InsecureSkipVerify: cfg.InsecureSkipVerify,
        MinVersion:         cfg.TLSMinVersion,
        MaxVersion:         cfg.TLSMaxVersion,
        // Cipher suite preferences for fingerprinting evasion
        CipherSuites: []uint16{
            tls.TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,
            tls.TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,
            tls.TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,
            tls.TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,
        },
    }
    
    // Custom dialer for connection tracking
    dialer := &net.Dialer{
        Timeout:   30 * time.Second,
        KeepAlive: 30 * time.Second,
    }
    
    // Configure transport
    transport := &http.Transport{
        Proxy:                 http.ProxyFromEnvironment,
        DialContext:           dialer.DialContext,
        TLSClientConfig:       tlsConfig,
        MaxIdleConns:          cfg.MaxIdleConns,
        MaxIdleConnsPerHost:   cfg.MaxConnsPerHost,
        IdleConnTimeout:       cfg.IdleConnTimeout,
        TLSHandshakeTimeout:   cfg.TLSHandshakeTimeout,
        DisableKeepAlives:     cfg.DisableKeepAlives,
        DisableCompression:    cfg.DisableCompression,
        ExpectContinueTimeout: 1 * time.Second,
        ResponseHeaderTimeout: 30 * time.Second,
    }
    
    // Set proxy if configured
    if cfg.ProxyURL != "" {
        proxyURL, err := url.Parse(cfg.ProxyURL)
        if err != nil {
            return nil, fmt.Errorf("invalid proxy URL: %w", err)
        }
        transport.Proxy = http.ProxyURL(proxyURL)
    }
    
    client := &http.Client{
        Transport: transport,
        Jar:       jar,
        Timeout:   cfg.Timeout,
        CheckRedirect: func(req *http.Request, via []*http.Request) error {
            // Limit redirects and track them
            if len(via) >= 10 {
                return fmt.Errorf("stopped after 10 redirects")
            }
            return nil
        },
    }
    
    // Initialize rate limiter
    rateLimiter := NewRateLimiter(cfg.RequestsPerSecond, cfg.BurstSize)
    
    return &ScannerHTTPClient{
        client:      client,
        transport:   transport,
        jar:         jar,
        rateLimiter: rateLimiter,
        cfg:         cfg,
    }, nil
}

// Do sends an HTTP request with retry logic and rate limiting
func (c *ScannerHTTPClient) Do(ctx context.Context, req *http.Request) (*http.Response, error) {
    // Wait for rate limiter
    if err := c.rateLimiter.Wait(ctx); err != nil {
        return nil, fmt.Errorf("rate limiter error: %w", err)
    }
    
    // Apply custom headers
    c.applyHeaders(req)
    
    var resp *http.Response
    var err error
    
    // Retry loop
    for attempt := 0; attempt <= c.cfg.MaxRetries; attempt++ {
        if attempt > 0 {
            // Exponential backoff
            backoff := c.calculateBackoff(attempt)
            select {
            case <-time.After(backoff):
            case <-ctx.Done():
                return nil, ctx.Err()
            }
        }
        
        // Clone request for retry safety
        reqClone := req.Clone(ctx)
        
        // Send request
        resp, err = c.client.Do(reqClone)
        if err != nil {
            // Check if error is retryable
            if !c.isRetryable(err) {
                return nil, err
            }
            continue
        }
        
        // Check if status code is retryable
        if c.shouldRetryStatus(resp.StatusCode) && attempt < c.cfg.MaxRetries {
            resp.Body.Close()
            continue
        }
        
        // Success
        c.trackResponse(resp)
        return resp, nil
    }
    
    return resp, err
}

func (c *ScannerHTTPClient) applyHeaders(req *http.Request) {
    if c.cfg.UserAgent != "" {
        req.Header.Set("User-Agent", c.cfg.UserAgent)
    }
    
    for k, v := range c.cfg.Headers {
        req.Header.Set(k, v)
    }
    
    // Anti-fingerprinting headers
    if req.Header.Get("Accept") == "" {
        req.Header.Set("Accept", "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8")
    }
    if req.Header.Get("Accept-Language") == "" {
        req.Header.Set("Accept-Language", "en-US,en;q=0.9")
    }
    if req.Header.Get("Accept-Encoding") == "" && !c.cfg.DisableCompression {
        req.Header.Set("Accept-Encoding", "gzip, deflate")
    }
}

func (c *ScannerHTTPClient) calculateBackoff(attempt int) time.Duration {
    backoff := c.cfg.RetryWaitMin * time.Duration(1<<uint(attempt))
    if backoff > c.cfg.RetryWaitMax {
        backoff = c.cfg.RetryWaitMax
    }
    return backoff
}

func (c *ScannerHTTPClient) isRetryable(err error) bool {
    // Network errors, timeouts are retryable
    if err == io.EOF || err == io.ErrUnexpectedEOF {
        return true
    }
    if netErr, ok := err.(net.Error); ok && netErr.Timeout() {
        return true
    }
    return false
}

func (c *ScannerHTTPClient) shouldRetryStatus(statusCode int) bool {
    // Retry on 5xx and specific 4xx errors
    return statusCode >= 500 || statusCode == 429 || statusCode == 408
}

func (c *ScannerHTTPClient) trackResponse(resp *http.Response) {
    c.mu.Lock()
    defer c.mu.Unlock()
    c.requestCount++
    if resp.ContentLength > 0 {
        c.bytesReceived += uint64(resp.ContentLength)
    }
}

// RateLimiter implements token bucket rate limiting
type RateLimiter struct {
    tokens      int
    maxTokens   int
    refillRate  int
    lastRefill  time.Time
    mu          sync.Mutex
}

func NewRateLimiter(requestsPerSecond, burstSize int) *RateLimiter {
    return &RateLimiter{
        tokens:     burstSize,
        maxTokens:  burstSize,
        refillRate: requestsPerSecond,
        lastRefill: time.Now(),
    }
}

func (rl *RateLimiter) Wait(ctx context.Context) error {
    for {
        rl.mu.Lock()
        rl.refill()
        
        if rl.tokens > 0 {
            rl.tokens--
            rl.mu.Unlock()
            return nil
        }
        rl.mu.Unlock()
        
        select {
        case <-time.After(10 * time.Millisecond):
            continue
        case <-ctx.Done():
            return ctx.Err()
        }
    }
}

func (rl *RateLimiter) refill() {
    now := time.Now()
    elapsed := now.Sub(rl.lastRefill)
    tokensToAdd := int(elapsed.Seconds() * float64(rl.refillRate))
    
    if tokensToAdd > 0 {
        rl.tokens += tokensToAdd
        if rl.tokens > rl.maxTokens {
            rl.tokens = rl.maxTokens
        }
        rl.lastRefill = now
    }
}
```

### B. Crawler Engine (Rust)

```rust
// src/crawler/engine.rs
use std::collections::{HashMap, HashSet, VecDeque};
use std::sync::Arc;
use tokio::sync::{RwLock, Semaphore};
use url::Url;
use scraper::{Html, Selector};
use regex::Regex;

#[derive(Debug, Clone)]
pub struct CrawlConfig {
    pub max_depth: usize,
    pub max_pages: usize,
    pub concurrent_requests: usize,
    pub follow_external: bool,
    pub extract_forms: bool,
    pub extract_comments: bool,
    pub extract_scripts: bool,
    pub respect_robots: bool,
    pub user_agent: String,
}

#[derive(Debug, Clone)]
pub struct CrawlResult {
    pub url: Url,
    pub status_code: u16,
    pub headers: HashMap<String, String>,
    pub body: String,
    pub links: Vec<Url>,
    pub forms: Vec<FormData>,
    pub depth: usize,
    pub crawl_time_ms: u64,
}

#[derive(Debug, Clone)]
pub struct FormData {
    pub action: String,
    pub method: String,
    pub inputs: Vec<InputField>,
}

#[derive(Debug, Clone)]
pub struct InputField {
    pub name: String,
    pub input_type: String,
    pub value: Option<String>,
}

pub struct CrawlerEngine {
    config: CrawlConfig,
    visited: Arc<RwLock<HashSet<String>>>,
    queue: Arc<RwLock<VecDeque<(Url, usize)>>>,
    results: Arc<RwLock<Vec<CrawlResult>>>,
    semaphore: Arc<Semaphore>,
    base_domain: String,
}

impl CrawlerEngine {
    pub fn new(config: CrawlConfig, start_url: Url) -> Self {
        let base_domain = start_url.host_str().unwrap_or("").to_string();
        let semaphore = Arc::new(Semaphore::new(config.concurrent_requests));
        
        Self {
            config,
            visited: Arc::new(RwLock::new(HashSet::new())),
            queue: Arc::new(RwLock::new(VecDeque::new())),
            results: Arc::new(RwLock::new(Vec::new())),
            semaphore,
            base_domain,
        }
    }
    
    pub async fn crawl(&self, start_url: Url) -> Result<Vec<CrawlResult>, Box<dyn std::error::Error>> {
        // Initialize queue with start URL
        {
            let mut queue = self.queue.write().await;
            queue.push_back((start_url, 0));
        }
        
        let mut tasks = Vec::new();
        
        loop {
            // Check if we're done
            let queue_empty = {
                let queue = self.queue.read().await;
                queue.is_empty()
            };
            
            if queue_empty && tasks.is_empty() {
                break;
            }
            
            // Pop URL from queue
            let url_depth = {
                let mut queue = self.queue.write().await;
                queue.pop_front()
            };
            
            if let Some((url, depth)) = url_depth {
                // Check if already visited
                {
                    let mut visited = self.visited.write().await;
                    let url_str = url.as_str().to_string();
                    if visited.contains(&url_str) {
                        continue;
                    }
                    visited.insert(url_str);
                }
                
                // Check depth limit
                if depth > self.config.max_depth {
                    continue;
                }
                
                // Check page limit
                {
                    let results = self.results.read().await;
                    if results.len() >= self.config.max_pages {
                        break;
                    }
                }
                
                // Spawn crawl task
                let engine_clone = self.clone_for_task();
                let permit = self.semaphore.clone().acquire_owned().await?;
                
                let task = tokio::spawn(async move {
                    let result = engine_clone.crawl_page(url.clone(), depth).await;
                    drop(permit);
                    result
                });
                
                tasks.push(task);
            }
            
            // Wait for some tasks to complete
            if tasks.len() >= self.config.concurrent_requests {
                if let Some(task) = tasks.pop() {
                    let _ = task.await;
                }
            }
        }
        
        // Wait for all remaining tasks
        for task in tasks {
            let _ = task.await;
        }
        
        // Return results
        let results = self.results.read().await;
        Ok(results.clone())
    }
    
    async fn crawl_page(&self, url: Url, depth: usize) -> Result<(), Box<dyn std::error::Error>> {
        let start_time = std::time::Instant::now();
        
        // Fetch page
        let client = reqwest::Client::builder()
            .user_agent(&self.config.user_agent)
            .timeout(std::time::Duration::from_secs(30))
            .build()?;
        
        let response = client.get(url.as_str()).send().await?;
        let status = response.status();
        let headers: HashMap<String, String> = response
            .headers()
            .iter()
            .map(|(k, v)| (k.to_string(), v.to_str().unwrap_or("").to_string()))
            .collect();
        
        let body = response.text().await?;
        
        // Parse HTML
        let document = Html::parse_document(&body);
        
        // Extract links
        let links = self.extract_links(&document, &url);
        
        // Extract forms if enabled
        let forms = if self.config.extract_forms {
            self.extract_forms(&document, &url)
        } else {
            Vec::new()
        };
        
        // Store result
        let crawl_time_ms = start_time.elapsed().as_millis() as u64;
        let result = CrawlResult {
            url: url.clone(),
            status_code: status.as_u16(),
            headers,
            body,
            links: links.clone(),
            forms,
            depth,
            crawl_time_ms,
        };
        
        {
            let mut results = self.results.write().await;
            results.push(result);
        }
        
        // Add discovered links to queue
        {
            let mut queue = self.queue.write().await;
            for link in links {
                if self.should_follow(&link) {
                    queue.push_back((link, depth + 1));
                }
            }
        }
        
        Ok(())
    }
    
    fn extract_links(&self, document: &Html, base_url: &Url) -> Vec<Url> {
        let mut links = Vec::new();
        
        // Extract from <a> tags
        if let Ok(selector) = Selector::parse("a[href]") {
            for element in document.select(&selector) {
                if let Some(href) = element.value().attr("href") {
                    if let Ok(absolute_url) = base_url.join(href) {
                        links.push(absolute_url);
                    }
                }
            }
        }
        
        // Extract from <link> tags
        if let Ok(selector) = Selector::parse("link[href]") {
            for element in document.select(&selector) {
                if let Some(href) = element.value().attr("href") {
                    if let Ok(absolute_url) = base_url.join(href) {
                        links.push(absolute_url);
                    }
                }
            }
        }
        
        // Extract from <script> tags
        if self.config.extract_scripts {
            if let Ok(selector) = Selector::parse("script[src]") {
                for element in document.select(&selector) {
                    if let Some(src) = element.value().attr("src") {
                        if let Ok(absolute_url) = base_url.join(src) {
                            links.push(absolute_url);
                        }
                    }
                }
            }
        }
        
        // Extract from <img> tags
        if let Ok(selector) = Selector::parse("img[src]") {
            for element in document.select(&selector) {
                if let Some(src) = element.value().attr("src") {
                    if let Ok(absolute_url) = base_url.join(src) {
                        links.push(absolute_url);
                    }
                }
            }
        }
        
        links
    }
    
    fn extract_forms(&self, document: &Html, base_url: &Url) -> Vec<FormData> {
        let mut forms = Vec::new();
        
        if let Ok(form_selector) = Selector::parse("form") {
            for form in document.select(&form_selector) {
                let action = form.value().attr("action")
                    .and_then(|a| base_url.join(a).ok())
                    .map(|u| u.to_string())
                    .unwrap_or_else(|| base_url.to_string());
                
                let method = form.value().attr("method")
                    .unwrap_or("GET")
                    .to_uppercase();
                
                let mut inputs = Vec::new();
                
                if let Ok(input_selector) = Selector::parse("input, textarea, select") {
                    for input in form.select(&input_selector) {
                        let name = input.value().attr("name")
                            .unwrap_or("")
                            .to_string();
                        let input_type = input.value().attr("type")
                            .unwrap_or("text")
                            .to_string();
                        let value = input.value().attr("value")
                            .map(|v| v.to_string());
                        
                        if !name.is_empty() {
                            inputs.push(InputField {
                                name,
                                input_type,
                                value,
                            });
                        }
                    }
                }
                
                forms.push(FormData {
                    action,
                    method,
                    inputs,
                });
            }
        }
        
        forms
    }
    
    fn should_follow(&self, url: &Url) -> bool {
        // Check if same domain or external following is enabled
        if !self.config.follow_external {
            if let Some(host) = url.host_str() {
                if host != self.base_domain {
                    return false;
                }
            }
        }
        
        // Filter out common static resources
        let path = url.path().to_lowercase();
        let static_extensions = [
            ".jpg", ".jpeg", ".png", ".gif", ".svg", ".ico",
            ".css", ".js", ".woff", ".woff2", ".ttf", ".eot",
            ".pdf", ".zip", ".tar", ".gz",
        ];
        
        for ext in &static_extensions {
            if path.ends_with(ext) {
                return false;
            }
        }
        
        true
    }
    
    fn clone_for_task(&self) -> Self {
        Self {
            config: self.config.clone(),
            visited: Arc::clone(&self.visited),
            queue: Arc::clone(&self.queue),
            results: Arc::clone(&self.results),
            semaphore: Arc::clone(&self.semaphore),
            base_domain: self.base_domain.clone(),
        }
    }
}
```

### C. Vulnerability Detection Engine (C++)

```cpp
// src/detection/sql_injection_detector.h
#ifndef SQL_INJECTION_DETECTOR_H
#define SQL_INJECTION_DETECTOR_H

#include <string>
#include <vector>
#include <regex>
#include <memory>
#include <unordered_map>

namespace scanner {
namespace detection {

enum class InjectionType {
    ERROR_BASED,
    BOOLEAN_BASED,
    TIME_BASED,
    UNION_BASED,
    STACKED_QUERIES,
    OUT_OF_BAND
};

struct DetectionResult {
    bool vulnerable;
    InjectionType type;
    std::string payload;
    std::string evidence;
    double confidence;
    std::string dbms_type;
};

class SQLInjectionDetector {
public:
    SQLInjectionDetector();
    ~SQLInjectionDetector() = default;
    
    // Main detection method
    DetectionResult detect(
        const std::string& url,
        const std::string& parameter,
        const std::string& original_response,
        std::function<std::string(const std::string&)> request_callback
    );
    
private:
    // Detection strategies
    DetectionResult detectErrorBased(
        const std::string& url,
        const std::string& parameter,
        std::function<std::string(const std::string&)> request_callback
    );
    
    DetectionResult detectBooleanBased(
        const std::string& url,
        const std::string& parameter,
        const std::string& original_response,
        std::function<std::string(const std::string&)> request_callback
    );
    
    DetectionResult detectTimeBased(
        const std::string& url,
        const std::string& parameter,
        std::function<std::string(const std::string&)> request_callback
    );
    
    DetectionResult detectUnionBased(
        const std::string& url,
        const std::string& parameter,
        std::function<std::string(const std::string&)> request_callback
    );
    
    // Helper methods
    std::string identifyDBMS(const std::string& error_message);
    double calculateConfidence(const DetectionResult& result);
    bool containsErrorSignature(const std::string& response);
    double calculateResponseSimilarity(const std::string& resp1, const std::string& resp2);
    
    // Payload generators
    std::vector<std::string> generateErrorPayloads(const std::string& dbms = "");
    std::vector<std::string> generateBooleanPayloads();
    std::vector<std::string> generateTimePayloads(const std::string& dbms);
    std::vector<std::string> generateUnionPayloads(int columns);
    
    // Error signatures database
    std::unordered_map<std::string, std::vector<std::regex>> error_signatures_;
    
    // Timing threshold for time-based detection
    static constexpr double TIME_THRESHOLD_MS = 5000.0;
};

// Implementation
SQLInjectionDetector::SQLInjectionDetector() {
    // Initialize error signatures for different DBMS
    error_signatures_["mysql"] = {
        std::regex(R"(SQL syntax.*?MySQL)", std::regex::icase),
        std::regex(R"(Warning.*?mysql_.*)", std::regex::icase),
        std::regex(R"(MySqlClient\.)", std::regex::icase),
        std::regex(R"(valid MySQL result)", std::regex::icase),
        std::regex(R"(check the manual that corresponds to your (MySQL|MariaDB))", std::regex::icase)
    };
    
    error_signatures_["postgresql"] = {
        std::regex(R"(PostgreSQL.*?ERROR)", std::regex::icase),
        std::regex(R"(Warning.*?pg_.*)", std::regex::icase),
        std::regex(R"(valid PostgreSQL result)", std::regex::icase),
        std::regex(R"(Npgsql\.)", std::regex::icase),
        std::regex(R"(PG::SyntaxError)", std::regex::icase)
    };
    
    error_signatures_["mssql"] = {
        std::regex(R"(Driver.*?SQL Server)", std::regex::icase),
        std::regex(R"(OLE DB.*?SQL Server)", std::regex::icase),
        std::regex(R"(\[Microsoft\]\[ODBC SQL Server Driver\])", std::regex::icase),
        std::regex(R"(\[SQL Server\])", std::regex::icase),
        std::regex(R"(Unclosed quotation mark after the character string)", std::regex::icase)
    };
    
    error_signatures_["oracle"] = {
        std::regex(R"(ORA-[0-9]{5})", std::regex::icase),
        std::regex(R"(Oracle error)", std::regex::icase),
        std::regex(R"(Oracle.*?Driver)", std::regex::icase),
        std::regex(R"(Warning.*?oci_.*)", std::regex::icase)
    };
}

DetectionResult SQLInjectionDetector::detect(
    const std::string& url,
    const std::string& parameter,
    const std::string& original_response,
    std::function<std::string(const std::string&)> request_callback
) {
    // Try different detection techniques in order of reliability
    
    // 1. Error-based (highest confidence)
    auto error_result = detectErrorBased(url, parameter, request_callback);
    if (error_result.vulnerable && error_result.confidence > 0.8) {
        return error_result;
    }
    
    // 2. Boolean-based
    auto boolean_result = detectBooleanBased(url, parameter, original_response, request_callback);
    if (boolean_result.vulnerable && boolean_result.confidence > 0.7) {
        return boolean_result;
    }
    
    // 3. Time-based
    auto time_result = detectTimeBased(url, parameter, request_callback);
    if (time_result.vulnerable && time_result.confidence > 0.7) {
        return time_result;
    }
    
    // 4. Union-based
    auto union_result = detectUnionBased(url, parameter, request_callback);
    if (union_result.vulnerable && union_result.confidence > 0.6) {
        return union_result;
    }
    
    // Return the best result even if below threshold
    std::vector<DetectionResult*> results = {
        &error_result, &boolean_result, &time_result, &union_result
    };
    
    auto best = std::max_element(results.begin(), results.end(),
        [](const DetectionResult* a, const DetectionResult* b) {
            return a->confidence < b->confidence;
        });
    
    return **best;
}

DetectionResult SQLInjectionDetector::detectErrorBased(
    const std::string& url,
    const std::string& parameter,
    std::function<std::string(const std::string&)> request_callback
) {
    DetectionResult result;
    result.vulnerable = false;
    result.type = InjectionType::ERROR_BASED;
    result.confidence = 0.0;
    
    // Generate error-inducing payloads
    auto payloads = generateErrorPayloads();
    
    for (const auto& payload : payloads) {
        std::string test_url = url + "&" + parameter + "=" + payload;
        std::string response = request_callback(test_url);
        
        if (containsErrorSignature(response)) {
            result.vulnerable = true;
            result.payload = payload;
            result.evidence = response.substr(0, 500); // First 500 chars
            result.dbms_type = identifyDBMS(response);
            result.confidence = 0.95; // High confidence for error-based
            return result;
        }
    }
    
    return result;
}

DetectionResult SQLInjectionDetector::detectBooleanBased(
    const std::string& url,
    const std::string& parameter,
    const std::string& original_response,
    std::function<std::string(const std::string&)> request_callback
) {
    DetectionResult result;
    result.vulnerable = false;
    result.type = InjectionType::BOOLEAN_BASED;
    result.confidence = 0.0;
    
    auto payloads = generateBooleanPayloads();
    
    // Test pairs: (true_condition, false_condition)
    std::vector<std::pair<std::string, std::string>> test_pairs = {
        {" AND 1=1", " AND 1=2"},
        {" OR 1=1", " OR 1=2"},
        {"' AND '1'='1", "' AND '1'='2"},
        {"' OR '1'='1", "' OR '1'='2"}
    };
    
    for (const auto& [true_payload, false_payload] : test_pairs) {
        std::string true_url = url + "&" + parameter + "=" + true_payload;
        std::string false_url = url + "&" + parameter + "=" + false_payload;
        
        std::string true_response = request_callback(true_url);
        std::string false_response = request_callback(false_url);
        
        // Calculate similarity between responses
        double true_similarity = calculateResponseSimilarity(original_response, true_response);
        double false_similarity = calculateResponseSimilarity(original_response, false_response);
        
        // If true_response is similar to original but false_response is different
        if (true_similarity > 0.9 && false_similarity < 0.7) {
            result.vulnerable = true;
            result.payload = true_payload + " / " + false_payload;
            result.evidence = "True similarity: " + std::to_string(true_similarity) + 
                            ", False similarity: " + std::to_string(false_similarity);
            result.confidence = std::abs(true_similarity - false_similarity);
            return result;
        }
    }
    
    return result;
}

DetectionResult SQLInjectionDetector::detectTimeBased(
    const std::string& url,
    const std::string& parameter,
    std::function<std::string(const std::string&)> request_callback
) {
    DetectionResult result;
    result.vulnerable = false;
    result.type = InjectionType::TIME_BASED;
    result.confidence = 0.0;
    
    // Test different DBMS time delay payloads
    std::vector<std::pair<std::string, std::string>> time_payloads = {
        {"'; WAITFOR DELAY '00:00:05'--", "mssql"},
        {"' AND SLEEP(5)--", "mysql"},
        {"'; SELECT pg_sleep(5)--", "postgresql"},
        {"' AND (SELECT * FROM (SELECT(SLEEP(5)))a)--", "mysql"},
    };
    
    for (const auto& [payload, dbms] : time_payloads) {
        std::string test_url = url + "&" + parameter + "=" + payload;
        
        auto start = std::chrono::high_resolution_clock::now();
        std::string response = request_callback(test_url);
        auto end = std::chrono::high_resolution_clock::now();
        
        auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);
        
        if (duration.count() >= TIME_THRESHOLD_MS) {
            result.vulnerable = true;
            result.payload = payload;
            result.dbms_type = dbms;
            result.evidence = "Response time: " + std::to_string(duration.count()) + "ms";
            result.confidence = std::min(0.9, duration.count() / TIME_THRESHOLD_MS * 0.7);
            return result;
        }
    }
    
    return result;
}

std::vector<std::string> SQLInjectionDetector::generateErrorPayloads(const std::string& dbms) {
    std::vector<std::string> payloads;
    
    // Generic payloads
    payloads.push_back("'");
    payloads.push_back("\"");
    payloads.push_back("')");
    payloads.push_back("\")");
    payloads.push_back("';");
    payloads.push_back("\";");
    
    // MySQL specific
    if (dbms.empty() || dbms == "mysql") {
        payloads.push_back("' AND EXTRACTVALUE(1, CONCAT(0x5c, (SELECT VERSION())))--");
        payloads.push_back("' AND (SELECT * FROM (SELECT COUNT(*),CONCAT((SELECT VERSION()),0x3a,FLOOR(RAND(0)*2))x FROM INFORMATION_SCHEMA.TABLES GROUP BY x)y)--");
    }
    
    // PostgreSQL specific
    if (dbms.empty() || dbms == "postgresql") {
        payloads.push_back("' AND CAST((SELECT VERSION()) AS INT)--");
    }
    
    // MSSQL specific
    if (dbms.empty() || dbms == "mssql") {
        payloads.push_back("' AND 1=CONVERT(INT, (SELECT @@VERSION))--");
    }
    
    return payloads;
}

std::string SQLInjectionDetector::identifyDBMS(const std::string& error_message) {
    for (const auto& [dbms, signatures] : error_signatures_) {
        for (const auto& regex : signatures) {
            if (std::regex_search(error_message, regex)) {
                return dbms;
            }
        }
    }
    return "unknown";
}

bool SQLInjectionDetector::containsErrorSignature(const std::string& response) {
    for (const auto& [dbms, signatures] : error_signatures_) {
        for (const auto& regex : signatures) {
            if (std::regex_search(response, regex)) {
                return true;
            }
        }
    }
    return false;
}

double SQLInjectionDetector::calculateResponseSimilarity(
    const std::string& resp1, 
    const std::string& resp2
) {
    // Simple Levenshtein-based similarity (simplified for brevity)
    // In production, use proper diff algorithms
    if (resp1 == resp2) return 1.0;
    
    size_t min_len = std::min(resp1.length(), resp2.length());
    size_t max_len = std::max(resp1.length(), resp2.length());
    
    if (max_len == 0) return 1.0;
    
    size_t differences = 0;
    for (size_t i = 0; i < min_len; ++i) {
        if (resp1[i] != resp2[i]) {
            differences++;
        }
    }
    
    differences += (max_len - min_len);
    
    return 1.0 - (static_cast<double>(differences) / max_len);
}

} // namespace detection
} // namespace scanner

#endif // SQL_INJECTION_DETECTOR_H
```

---

## III. Advanced Detection Techniques

### A. XSS Detection Engine (Python)

```python
# scanner/detectors/xss_detector.py

import re
import html
import hashlib
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass
from enum import Enum
import random
import string

class XSSType(Enum):
    REFLECTED = "reflected"
    STORED = "stored"
    DOM_BASED = "dom_based"
    MUTATION_BASED = "mutation_based"

@dataclass
class XSSDetectionResult:
    vulnerable: bool
    xss_type: XSSType
    payload: str
    context: str
    evidence: str
    confidence: float
    bypass_filters: List[str]

class XSSDetector:
    """Advanced XSS detection with context-aware payloads and mutation testing"""
    
    def __init__(self):
        self.canary_prefix = "xss_" + ''.join(random.choices(string.ascii_lowercase, k=8))
        
        # Context-aware payloads
        self.payloads = {
            'html': self._generate_html_payloads(),
            'attribute': self._generate_attribute_payloads(),
            'script': self._generate_script_payloads(),
            'event_handler': self._generate_event_handler_payloads(),
            'url': self._generate_url_payloads()
        }
        
        # WAF bypass techniques
        self.bypass_techniques = {
            'encoding': self._generate_encoded_payloads,
            'mutation': self._generate_mutation_payloads,
            'polyglot': self._generate_polyglot_payloads,
        }
    
    def detect(self, 
               url: str, 
               param: str, 
               request_func,
               original_response: str) -> XSSDetectionResult:
        """Main detection method with multi-context analysis"""
        
        # Generate unique canary
        canary = self._generate_canary()
        
        # Test canary injection
        canary_url = f"{url}&{param}={canary}"
        canary_response = request_func(canary_url)
        
        # Identify injection context
        context = self._identify_context(canary_response, canary)
        
        # Select appropriate payloads based on context
        context_payloads = self.payloads.get(context, self.payloads['html'])
        
        # Test each payload
        for payload in context_payloads:
            test_url = f"{url}&{param}={payload}"
            response = request_func(test_url)
            
            # Check if payload executed
            if self._is_vulnerable(response, payload, context):
                return XSSDetectionResult(
                    vulnerable=True,
                    xss_type=XSSType.REFLECTED,
                    payload=payload,
                    context=context,
                    evidence=self._extract_evidence(response, payload),
                    confidence=0.9,
                    bypass_filters=[]
                )
        
        # If basic payloads failed, try bypass techniques
        for technique_name, technique_func in self.bypass_techniques.items():
            bypass_payloads = technique_func(context)
            for payload in bypass_payloads:
                test_url = f"{url}&{param}={payload}"
                response = request_func(test_url)
                
                if self._is_vulnerable(response, payload, context):
                    return XSSDetectionResult(
                        vulnerable=True,
                        xss_type=XSSType.REFLECTED,
                        payload=payload,
                        context=context,
                        evidence=self._extract_evidence(response, payload),
                        confidence=0.85,
                        bypass_filters=[technique_name]
                    )
        
        return XSSDetectionResult(
            vulnerable=False,
            xss_type=XSSType.REFLECTED,
            payload="",
            context=context,
            evidence="",
            confidence=0.0,
            bypass_filters=[]
        )
    
    def _generate_canary(self) -> str:
        """Generate unique canary for context identification"""
        random_suffix = ''.join(random.choices(string.ascii_lowercase + string.digits, k=8))
        return f"{self.canary_prefix}_{random_suffix}"
    
    def _identify_context(self, response: str, canary: str) -> str:
        """Identify where the input is reflected in the response"""
        
        # Check if in HTML body
        if canary in response:
            # Extract surrounding context
            idx = response.find(canary)
            context_start = max(0, idx - 50)
            context_end = min(len(response), idx + len(canary) + 50)
            context_snippet = response[context_start:context_end]
            
            # Determine specific context
            if re.search(r'<script[^>]*>.*?' + re.escape(canary), response, re.DOTALL):
                return 'script'
            elif re.search(r'on\w+\s*=\s*["\'].*?' + re.escape(canary), response):
                return 'event_handler'
            elif re.search(r'<\w+[^>]*\s+\w+\s*=\s*["\'].*?' + re.escape(canary), response):
                return 'attribute'
            elif re.search(r'href\s*=\s*["\'].*?' + re.escape(canary), response):
                return 'url'
            else:
                return 'html'
        
        return 'html'
    
    def _generate_html_payloads(self) -> List[str]:
        """Generate HTML context payloads"""
        return [
            "<script>alert(1)</script>",
            "<img src=x onerror=alert(1)>",
            "<svg/onload=alert(1)>",
            "<iframe src=javascript:alert(1)>",
            "<body onload=alert(1)>",
            "<input onfocus=alert(1) autofocus>",
            "<select onfocus=alert(1) autofocus>",
            "<textarea onfocus=alert(1) autofocus>",
            "<marquee onstart=alert(1)>",
            "<div onwheel=alert(1)>test</div>",
        ]
    
    def _generate_attribute_payloads(self) -> List[str]:
        """Generate attribute context payloads"""
        return [
            "\" onload=\"alert(1)",
            "' onload='alert(1)",
            "\" autofocus onfocus=\"alert(1)",
            "' autofocus onfocus='alert(1)",
            "\"><script>alert(1)</script>",
            "'><script>alert(1)</script>",
            "\" onerror=\"alert(1)\" src=\"x",
            "' onerror='alert(1)' src='x",
        ]
    
    def _generate_script_payloads(self) -> List[str]:
        """Generate script context payloads"""
        return [
            "';alert(1);//",
            "\";alert(1);//",
            "';alert(1);var a='",
            "\";alert(1);var a=\"",
            "</script><script>alert(1)</script>",
            "-alert(1)-",
            "${alert(1)}",
        ]
    
    def _generate_event_handler_payloads(self) -> List[str]:
        """Generate event handler context payloads"""
        return [
            "alert(1)",
            "javascript:alert(1)",
            "alert(1)//",
            "alert(1);",
            "';alert(1);//",
            "\";alert(1);//",
        ]
    
    def _generate_url_payloads(self) -> List[str]:
        """Generate URL context payloads"""
        return [
            "javascript:alert(1)",
            "data:text/html,<script>alert(1)</script>",
            "vbscript:msgbox(1)",
            "javascript:alert(String.fromCharCode(88,83,83))",
        ]
    
    def _generate_encoded_payloads(self, context: str) -> List[str]:
        """Generate encoded payloads for WAF bypass"""
        payloads = []
        base_payload = "<script>alert(1)</script>"
        
        # HTML entity encoding
        payloads.append(''.join(f'&#{ord(c)};' for c in base_payload))
        
        # URL encoding
        payloads.append(''.join(f'%{ord(c):02x}' for c in base_payload))
        
        # Double URL encoding
        payloads.append(''.join(f'%25{ord(c):02x}' for c in base_payload))
        
        # Mixed case
        payloads.append("<ScRiPt>alert(1)</ScRiPt>")
        
        # Unicode encoding
        payloads.append(''.join(f'\\u{ord(c):04x}' for c in "alert(1)"))
        
        return payloads
    
    def _generate_mutation_payloads(self, context: str) -> List[str]:
        """Generate mutation-based payloads"""
        return [
            "<svg><script>alert(1)</script>",
            "<math><script>alert(1)</script>",
            "<table><script>alert(1)</script></table>",
            "<<script>script>alert(1)<</script>/script>",
            "<scr<script>ipt>alert(1)</scr</script>ipt>",
            "<img src=x onerror=\\u0061lert(1)>",
            "<img src=x onerror=\\x61lert(1)>",
        ]
    
    def _generate_polyglot_payloads(self, context: str) -> List[str]:
        """Generate polyglot payloads that work in multiple contexts"""
        return [
            "javascript:/*--></title></style></textarea></script></xmp>"
            "<svg/onload='+/\"/+/onmouseover=1/+/[*/[]/+alert(1)//'>",
            "'\"><img src=x onerror=alert(1)>",
            "';alert(String.fromCharCode(88,83,83))//';alert(String.fromCharCode(88,83,83))//\";"
            "alert(String.fromCharCode(88,83,83))//\";alert(String.fromCharCode(88,83,83))//--",
        ]
    
    def _is_vulnerable(self, response: str, payload: str, context: str) -> bool:
        """Check if the response indicates successful XSS"""
        
        # Check for unescaped payload
        if payload in response:
            return True
        
        # Check for partial payload (some characters escaped)
        # Look for key indicators
        indicators = ['<script', 'onerror=', 'onload=', 'javascript:', 'alert(']
        for indicator in indicators:
            if indicator in payload.lower() and indicator in response.lower():
                # Verify it's not HTML-escaped
                if not (html.escape(indicator) in response):
                    return True
        
        return False
    
    def _extract_evidence(self, response: str, payload: str) -> str:
        """Extract evidence of vulnerability from response"""
        idx = response.find(payload)
        if idx != -1:
            start = max(0, idx - 100)
            end = min(len(response), idx + len(payload) + 100)
            return response[start:end]
        return ""
```

---

## IV. Threat Model & Security Architecture

```
┌────────────────────────────────────────────────────────────┐
│                 Vulnerability Scanner Threat Model          │
└────────────────────────────────────────────────────────────┘

╔══════════════════════════════════════════════════════════╗
║                    TRUST BOUNDARIES                       ║
╠══════════════════════════════════════════════════════════╣
║                                                           ║
║  ┌─────────────┐         ┌─────────────┐                ║
║  │   Scanner   │────────▶│   Target    │                ║
║  │   Operator  │         │   Website   │                ║
║  └─────────────┘         └─────────────┘                ║
║        │                        │                        ║
║        │ Authorization          │ Attack Surface        ║
║        │ Scope Definition       │ Public/Private        ║
║        │                        │                        ║
║  ┌─────▼────────────────────────▼─────┐                 ║
║  │     Scanner Infrastructure          │                 ║
║  │  • HTTP Client                      │                 ║
║  │  • Crawler Engine                   │                 ║
║  │  • Detection Modules                │                 ║
║  │  • Payload Database                 │                 ║
║  │  • Results Storage                  │                 ║
║  └────────────────────────────────────┘                  ║
╚══════════════════════════════════════════════════════════╝

╔══════════════════════════════════════════════════════════╗
║                    THREAT SCENARIOS                       ║
╠══════════════════════════════════════════════════════════╣
║                                                           ║
║ T1: UNAUTHORIZED SCANNING                                ║
║  ├─ Attacker runs scanner against unauthorized targets   ║
║  ├─ Mitigation: Scope validation, authorization tokens   ║
║  └─ Impact: Legal liability, service disruption          ║
║                                                           ║
║ T2: SCANNER COMPROMISE                                   ║
║  ├─ Attacker exploits scanner vulnerabilities            ║
║  ├─ Mitigation: Input validation, sandboxing, least priv║
║  └─ Impact: False results, scanner as attack vector      ║
║                                                           ║
║ T3: DETECTION EVASION                                    ║
║  ├─ WAF/IDS blocks scanner, preventing detection         ║
║  ├─ Mitigation: Rate limiting, User-Agent rotation       ║
║  └─ Impact: False negatives, incomplete scans            ║
║                                                           ║
║ T4: DATA EXFILTRATION                                    ║
║  ├─ Scanner extracts sensitive data during crawling      ║
║  ├─ Mitigation: Scope limits, data sanitization          ║
║  └─ Impact: Privacy breach, data exposure                ║
║                                                           ║
║ T5: FALSE POSITIVE INJECTION                             ║
║  ├─ Target manipulates responses to trigger false alerts ║
║  ├─ Mitigation: Multiple verification, confidence scores ║
║  └─ Impact: Resource waste, credibility loss             ║
║                                                           ║
║ T6: DENIAL OF SERVICE                                    ║
║  ├─ Scanner overwhelms target with requests              ║
║  ├─ Mitigation: Rate limiting, concurrent request limits ║
║  └─ Impact: Service disruption, legal issues             ║
╚══════════════════════════════════════════════════════════╝

╔══════════════════════════════════════════════════════════╗
║                 SECURITY CONTROLS                         ║
╠══════════════════════════════════════════════════════════╣
║                                                           ║
║ INPUT VALIDATION                                         ║
║  ├─ Validate target URLs against scope                   ║
║  ├─ Sanitize payloads before injection                   ║
║  └─ Verify authorization tokens                          ║
║                                                           ║
║ ISOLATION                                                ║
║  ├─ Run scanner in containerized environment             ║
║  ├─ Separate crawling from detection engines             ║
║  └─ Network segmentation for scanner infrastructure      ║
║                                                           ║
║ RATE LIMITING                                            ║
║  ├─ Implement token bucket algorithm                     ║
║  ├─ Adaptive rate limiting based on target response      ║
║  └─ Concurrent request limits per domain                 ║
║                                                           ║
║ AUDIT LOGGING                                            ║
║  ├─ Log all scan activities with timestamps              ║
║  ├─ Record operator actions and authorization            ║
║  └─ Immutable log storage for compliance                 ║
║                                                           ║
║ DATA PROTECTION                                          ║
║  ├─ Encrypt results at rest and in transit               ║
║  ├─ Sanitize sensitive data before storage               ║
║  └─ Implement data retention policies                    ║
╚══════════════════════════════════════════════════════════╝
```

---

## V. Production Deployment Architecture

```yaml
# deployment/kubernetes/scanner-deployment.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: vuln-scanner
  labels:
    name: vuln-scanner
    security: restricted

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: scanner-config
  namespace: vuln-scanner
data:
  config.yaml: |
    scanner:
      max_depth: 5
      max_pages: 1000
      concurrent_workers: 10
      request_timeout: 30s
      rate_limit:
        requests_per_second: 10
        burst_size: 20
      
      # Detection modules
      modules:
        - name: sql_injection
          enabled: true
          confidence_threshold: 0.7
        - name: xss
          enabled: true
          confidence_threshold: 0.7
        - name: ssrf
          enabled: true
          confidence_threshold: 0.8
        - name: path_traversal
          enabled: true
          confidence_threshold: 0.7
      
      # Security settings
      security:
        require_authorization: true
        scope_validation: true
        max_payload_size: 10KB
        
      # Logging
      logging:
        level: info
        format: json
        audit_enabled: true

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vuln-scanner
  namespace: vuln-scanner
spec:
  replicas: 3
  selector:
    matchLabels:
      app: vuln-scanner
  template:
    metadata:
      labels:
        app: vuln-scanner
      annotations:
        container.apparmor.security.beta.kubernetes.io/scanner: runtime/default
    spec:
      serviceAccountName: scanner-sa
      securityContext:
        runAsNonRoot: true
        runAsUser: 65534
        fsGroup: 65534
        seccompProfile:
          type: RuntimeDefault
      
      containers:
      - name: scanner
        image: scanner:latest
        imagePullPolicy: Always
        
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          capabilities:
            drop:
            - ALL
        
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "2000m"
        
        ports:
        - name: http
          containerPort: 8080
          protocol: TCP
        - name: metrics
          containerPort: 9090
          protocol: TCP
        
        env:
        - name: CONFIG_PATH
          value: /config/config.yaml
        - name: LOG_LEVEL
          value: info
        
        volumeMounts:
        - name: config
          mountPath: /config
          readOnly: true
        - name: tmp
          mountPath: /tmp
        - name: cache
          mountPath: /cache
        
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
      
      volumes:
      - name: config
        configMap:
          name: scanner-config
      - name: tmp
        emptyDir: {}
      - name: cache
        emptyDir: {}

---
apiVersion: v1
kind: Service
metadata:
  name: scanner-service
  namespace: vuln-scanner
spec:
  selector:
    app: vuln-scanner
  ports:
  - name: http
    port: 80
    targetPort: 8080
  - name: metrics
    port: 9090
    targetPort: 9090
  type: ClusterIP

---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: scanner-netpol
  namespace: vuln-scanner
spec:
  podSelector:
    matchLabels:
      app: vuln-scanner
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: scanner-api
    ports:
    - protocol: TCP
      port: 8080
  egress:
  - to:
    - namespaceSelector: {}
    ports:
    - protocol: TCP
      port: 53  # DNS
  - to:
    - podSelector: {}
    ports:
    - protocol: TCP
      port: 443  # HTTPS for scanning
    - protocol: TCP
      port: 80   # HTTP for scanning

---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: scanner-pdb
  namespace: vuln-scanner
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: vuln-scanner
```

---

## VI. Testing & Validation

### A. Fuzzing Scanner Components

```go
// tests/fuzz/crawler_fuzz_test.go
//go:build gofuzz
// +build gofuzz

package fuzz

import (
    "bytes"
    "testing"
    
    "github.com/yourusername/scanner/pkg/crawler"
)

func FuzzURLParser(f *testing.F) {
    // Seed corpus with valid and invalid URLs
    f.Add("http://example.com")
    f.Add("https://example.com/path?param=value")
    f.Add("javascript:alert(1)")
    f.Add("data:text/html,<script>alert(1)</script>")
    f.Add("file:///etc/passwd")
    f.Add("gopher://example.com")
    
    f.Fuzz(func(t *testing.T, url string) {
        // Test URL parsing doesn't panic
        defer func() {
            if r := recover(); r != nil {
                t.Errorf("URL parser panicked on input: %s", url)
            }
        }()
        
        _ = crawler.ParseURL(url)
    })
}

func FuzzHTMLParser(f *testing.F) {
    // Seed corpus with various HTML structures
    f.Add("<html><body><a href='test'>link</a></body></html>")
    f.Add("<html><script>alert(1)</script></html>")
    f.Add("<!DOCTYPE html><html><body></body></html>")
    f.Add("<html><form action='/test'><input name='test'/></form></html>")
    
    f.Fuzz(func(t *testing.T, html string) {
        defer func() {
            if r := recover(); r != nil {
                t.Errorf("HTML parser panicked on input: %s", html)
            }
        }()
        
        _ = crawler.ParseHTML([]byte(html))
    })
}

func FuzzPayloadGenerator(f *testing.F) {
    f.Add("param", "value")
    f.Add("id", "1")
    f.Add("search", "test")
    
    f.Fuzz(func(t *testing.T, param, value string) {
        defer func() {
            if r := recover(); r != nil {
                t.Errorf("Payload generator panicked: param=%s, value=%s", param, value)
            }
        }()
        
        payloads := crawler.GenerateSQLInjectionPayloads(param, value)
        
        // Verify payloads don't exceed size limits
        for _, payload := range payloads {
            if len(payload) > 10000 {
                t.Errorf("Payload exceeds size limit: %d bytes", len(payload))
            }
        }
    })
}
```

### B. Integration Tests

```python
# tests/integration/test_scanner_e2e.py

import pytest
import requests
from scanner import VulnerabilityScanner
from test_server import create_vulnerable_app

class TestScannerE2E:
    """End-to-end tests using vulnerable test applications"""
    
    @pytest.fixture
    def vulnerable_app(self):
        """Start a vulnerable test application"""
        app = create_vulnerable_app()
        app.run(port=8888, threaded=True)
        yield "http://localhost:8888"
        app.stop()
    
    def test_sql_injection_detection(self, vulnerable_app):
        """Test SQL injection detection on known vulnerable endpoint"""
        scanner = VulnerabilityScanner()
        results = scanner.scan(
            target_url=f"{vulnerable_app}/products?id=1",
            modules=["sql_injection"]
        )
        
        assert len(results) > 0
        assert any(r.vulnerability_type == "SQL_INJECTION" for r in results)
        assert results[0].confidence > 0.8
    
    def test_xss_detection(self, vulnerable_app):
        """Test XSS detection on known vulnerable endpoint"""
        scanner = VulnerabilityScanner()
        results = scanner.scan(
            target_url=f"{vulnerable_app}/search?q=test",
            modules=["xss"]
        )
        
        assert len(results) > 0
        assert any(r.vulnerability_type == "XSS" for r in results)
    
    def test_false_positive_rate(self, vulnerable_app):
        """Test false positive rate on hardened endpoints"""
        scanner = VulnerabilityScanner()
        results = scanner.scan(
            target_url=f"{vulnerable_app}/secure/products?id=1",
            modules=["sql_injection", "xss"]
        )
        
        # Secure endpoint should not trigger vulnerabilities
        assert len(results) == 0
    
    def test_rate_limiting_compliance(self, vulnerable_app):
        """Test that scanner respects rate limits"""
        import time
        scanner = VulnerabilityScanner(config={
            "rate_limit": {"requests_per_second": 10}
        })
        
        start_time = time.time()
        scanner.scan(
            target_url=f"{vulnerable_app}/products",
            max_pages=100
        )
        elapsed = time.time() - start_time
        
        # Should take at least 10 seconds for 100 requests at 10 req/s
        assert elapsed >= 9.0
    
    def test_scope_compliance(self, vulnerable_app):
        """Test that scanner respects scope boundaries"""
        scanner = VulnerabilityScanner(config={
            "allowed_domains": ["localhost"]
        })
        
        results = scanner.scan(target_url=vulnerable_app)
        
        # Verify all discovered URLs are within scope
        for result in results:
            assert "localhost" in result.url
```

---

## VII. Benchmarking & Performance

```rust
// benches/scanner_bench.rs

use criterion::{black_box, criterion_group, criterion_main, Criterion, BenchmarkId};
use scanner::crawler::CrawlerEngine;
use scanner::detection::SQLInjectionDetector;

fn bench_crawler_performance(c: &mut Criterion) {
    let mut group = c.benchmark_group("crawler");
    
    for page_count in [10, 100, 1000].iter() {
        group.bench_with_input(
            BenchmarkId::from_parameter(page_count),
            page_count,
            |b, &page_count| {
                b.iter(|| {
                    let crawler = CrawlerEngine::new(/* config */);
                    black_box(crawler.crawl(page_count))
                });
            },
        );
    }
    
    group.finish();
}

fn bench_sql_detection(c: &mut Criterion) {
    let mut group = c.benchmark_group("sql_injection_detection");
    
    let detector = SQLInjectionDetector::new();
    let test_url = "http://example.com/products?id=1";
    
    group.bench_function("error_based", |b| {
        b.iter(|| {
            black_box(detector.detect_error_based(test_url))
        });
    });
    
    group.bench_function("time_based", |b| {
        b.iter(|| {
            black_box(detector.detect_time_based(test_url))
        });
    });
    
    group.finish();
}

fn bench_payload_generation(c: &mut Criterion) {
    let mut group = c.benchmark_group("payload_generation");
    
    group.bench_function("sql_payloads", |b| {
        b.iter(|| {
            black_box(generate_sql_injection_payloads())
        });
    });
    
    group.bench_function("xss_payloads", |b| {
        b.iter(|| {
            black_box(generate_xss_payloads())
        });
    });
    
    group.finish();
}

criterion_group!(benches, 
    bench_crawler_performance,
    bench_sql_detection,
    bench_payload_generation
);
criterion_main!(benches);
```

---

## VIII. Build, Test, Run Commands

```bash
# Build Scanner (Multi-language project)

# 1. Rust components
cd rust-components/
cargo build --release
cargo test --all-features
cargo clippy -- -D warnings

# 2. Go components
cd ../go-components/
go build -o bin/scanner ./cmd/scanner
go test -race -coverprofile=coverage.out ./...
go test -bench=. -benchmem ./...

# 3. C++ components
cd ../cpp-components/
mkdir -p build && cd build
cmake -DCMAKE_BUILD_TYPE=Release ..
make -j$(nproc)
ctest --output-on-failure

# 4. Python components
cd ../../python-components/
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
pytest tests/ -v --cov=scanner

# Run Scanner
./bin/scanner scan \
  --target https://example.com \
  --modules sql_injection,xss,ssrf \
  --max-depth 5 \
  --concurrent-workers 10 \
  --output report.json

# Run with Docker
docker build -t vuln-scanner:latest .
docker run --rm \
  --security-opt=no-new-privileges \
  --cap-drop=ALL \
  --read-only \
  vuln-scanner:latest \
  scan --target https://example.com

# Deploy to Kubernetes
kubectl create namespace vuln-scanner
kubectl apply -f deployment/kubernetes/
kubectl -n vuln-scanner get pods
kubectl -n vuln-scanner logs -f <pod-name>

# Run fuzzing tests
go test -fuzz=FuzzURLParser -fuzztime=30s
cargo fuzz run fuzz_html_parser -- -max_total_time=60

# Performance profiling
go test -cpuprofile cpu.prof -memprofile mem.prof -bench=.
go tool pprof cpu.prof
```

---

## IX. Next 3 Steps

**STEP 1: Core Engine Implementation (Week 1-2)**
- Implement HTTP client layer with TLS fingerprinting, cookie management, and retry logic
- Build crawler engine with parallel worker pool, URL normalization, and robots.txt parsing
- Create detection engines for SQLi, XSS, SSRF with signature databases
- Commands:
  ```bash
  # Initialize project structure
  mkdir -p {cmd,pkg,internal,tests}/{crawler,detection,httpclient}
  go mod init github.com/youruser/vuln-scanner
  
  # Start with HTTP client
  touch pkg/httpclient/{client.go,ratelimiter.go,client_test.go}
  ```

**STEP 2: Detection & Testing (Week 3-4)**
- Implement vulnerability-specific detectors with multiple detection techniques
- Add payload generators with WAF bypass capabilities
- Write comprehensive unit tests, integration tests, and fuzz tests
- Build vulnerable test applications for validation
- Commands:
  ```bash
  # Run test suite
  go test ./... -race -cover
  pytest tests/ --cov=scanner --cov-report=html
  cargo test --all-features
  
  # Start test vulnerable app
  python tests/vulnerable_app.py &
  ./bin/scanner scan --target http://localhost:8888
  ```

**STEP 3: Production Hardening & Deployment (Week 5-6)**
- Implement security controls: scope validation, audit logging, data encryption
- Create Kubernetes manifests with network policies, security contexts, resource limits
- Build CI/CD pipeline with SAST, dependency scanning, container scanning
- Deploy to staging environment and run penetration tests
- Commands:
  ```bash
  # Build container
  docker build --security-opt=no-new-privileges -t scanner:v1.0 .
  
  # Security scanning
  trivy image scanner:v1.0
  grype scanner:v1.0
  
  # Deploy to K8s
  kubectl apply -f deployment/kubernetes/
  kubectl -n vuln-scanner port-forward svc/scanner-service 8080:80
  ```

---

## X. References & Resources

**Academic Papers:**
- "Black-Box Web Application Vulnerability Scanners: Detection and Detection Evasion" (NDSS)
- "Why Johnny Can't Pentest: Analysis of Black-box Web Vulnerability Scanners" (IEEE S&P)
- "NAVEX: Precise and Scalable Exploit Generation for Dynamic Web Applications" (USENIX Security)

**Industry Standards:**
- OWASP Testing Guide v4.2: https://owasp.org/www-project-web-security-testing-guide/
- WASC Threat Classification: http://projects.webappsec.org/Threat-Classification
- CWE/SANS Top 25: https://cwe.mitre.org/top25/

**Open Source Scanners:**
- SQLMap: https://github.com/sqlmapproject/sqlmap
- Burp Suite (Community): https://portswigger.net/burp/communitydownload
- OWASP ZAP: https://www.zaproxy.org/
- Nuclei: https://github.com/projectdiscovery/nuclei
- Nikto: https://github.com/sullo/nikto

**CNCF Integration:**
- Falco (Runtime Security): https://falco.org/
- Open Policy Agent: https://www.openpolicyagent.org/
- Cert-Manager (TLS): https://cert-manager.io/

**Books:**
- "The Web Application Hacker's Handbook" - Stuttard & Pinto
- "Real-World Bug Hunting" - Peter Yaworski
- "Tangled Web" - Michal Zalewski (Browser security internals)

**Protocol Specifications:**
- RFC 7230-7235 (HTTP/1.1): https://tools.ietf.org/html/rfc7230
- RFC 7540 (HTTP/2): https://tools.ietf.org/html/rfc7540
- RFC 8446 (TLS 1.3): https://tools.ietf.org/html/rfc8446

This guide provides production-grade foundation for building a secure, scalable vulnerability scanner with deep technical understanding of web application security testing.