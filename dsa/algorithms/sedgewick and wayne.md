# The Complete Sedgewick & Wayne "Algorithms" Mastery Guide
## A Monk's Path to Top 1% Algorithmic Excellence

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  "An algorithm must be seen to be believed." â€” Donald Knuth â”‚
â”‚                                                               â”‚
â”‚  Your Journey: Fundamentals â†’ Mastery â†’ Top 1% Excellence   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“š **Overview: What Makes This Book Essential**

Sedgewick & Wayne's "Algorithms" is the **definitive modern algorithms text** used at Princeton and worldwide. It covers:

- **Fundamental data structures** (bags, stacks, queues, priority queues, symbol tables)
- **Sorting algorithms** (elementary sorts, mergesort, quicksort, heapsort)
- **Searching** (binary search trees, balanced trees, hash tables)
- **Graphs** (undirected/directed graphs, MSTs, shortest paths)
- **Strings** (sorts, tries, substring search, compression, regex)
- **Advanced topics** (context, reductions, intractability)

**Why this approach matters for top 1%:**
- Emphasis on **scientific method**: hypothesis, experiment, analyze
- **Real-world performance analysis**, not just Big-O theory
- **API-first design** thinking
- Focus on **practical implementations** that work in production

---

## ğŸ§­ **Learning Strategy: The Monk's Approach**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LEARNING ARCHITECTURE                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  1. UNDERSTAND THE PROBLEM                                   â”‚
â”‚     â†“                                                         â”‚
â”‚  2. ANALYZE THE ABSTRACT DATA TYPE (API)                     â”‚
â”‚     â†“                                                         â”‚
â”‚  3. STUDY NAIVE IMPLEMENTATION                               â”‚
â”‚     â†“                                                         â”‚
â”‚  4. IDENTIFY PERFORMANCE BOTTLENECKS                         â”‚
â”‚     â†“                                                         â”‚
â”‚  5. LEARN OPTIMIZED SOLUTIONS                                â”‚
â”‚     â†“                                                         â”‚
â”‚  6. IMPLEMENT IN MULTIPLE LANGUAGES                          â”‚
â”‚     â†“                                                         â”‚
â”‚  7. ANALYZE PERFORMANCE EMPIRICALLY                          â”‚
â”‚     â†“                                                         â”‚
â”‚  8. SOLVE RELATED PROBLEMS                                   â”‚
â”‚     â†“                                                         â”‚
â”‚  9. TEACH/EXPLAIN TO SOLIDIFY                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Mental Model: Chunking**
- Break each topic into digestible "chunks" (e.g., "insertion sort" is one chunk)
- Master one chunk completely before moving forward
- Link chunks together (e.g., "merge" operation links to mergesort, external sorting, etc.)

---

## ğŸ“– **PART I: FUNDAMENTALS**

### **Chapter 1.1: Basic Programming Model**

**Core Concepts:**
- **Primitive data types**: integers, floats, booleans, characters
- **Control flow**: conditionals, loops, recursion
- **Arrays**: fixed-size collections
- **Static methods**: encapsulated reusable procedures

**Key Insight for Top 1%:**
Everything in algorithms builds on **three fundamental operations**:
1. **Sequence** (do A, then B)
2. **Selection** (if-else)
3. **Iteration** (loops, recursion)

These are your **atomic building blocks**.

---

### **Chapter 1.2: Data Abstraction**

**What is an Abstract Data Type (ADT)?**
An ADT defines:
1. **What** operations are supported (API)
2. **Not how** they're implemented (implementation details hidden)

**Example: Counter ADT**
```
API:
- Counter(String name)  // constructor
- void increment()       // add 1 to count
- int tally()           // return current count
- String toString()     // string representation
```

**Why ADTs Matter:**
- **Separation of concerns**: client code doesn't depend on implementation
- **Flexibility**: can swap implementations without changing client code
- **Reusability**: same interface, multiple contexts

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            ADT THINKING PATTERN                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                 â”‚
â”‚  Problem â†’ What operations do I need? â†’ API    â”‚
â”‚     â†“                                           â”‚
â”‚  How to implement efficiently? â†’ Data Structureâ”‚
â”‚     â†“                                           â”‚
â”‚  How does it perform? â†’ Analysis               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Cognitive Principle: Abstraction**
Your brain can only hold ~7 items in working memory. ADTs let you think at higher levels without drowning in details.

---

### **Chapter 1.3: Bags, Queues, and Stacks**

These are **fundamental collection types** you'll use everywhere.

#### **1.3.1: Bag (Unordered Collection)**

**What is it?**
A collection where:
- Order doesn't matter
- Duplicates allowed
- Can add items
- Can iterate through items (in arbitrary order)
- Cannot remove specific items

**API:**
```
Bag<Item>
- Bag()              // create empty bag
- void add(Item item)// add an item
- boolean isEmpty()  // is bag empty?
- int size()        // number of items
- Iterator<Item> iterator() // iterate over items
```

**Use Case:**
Reading marks from a file to compute statistics (order irrelevant).

---

#### **1.3.2: Queue (FIFO - First In First Out)**

**What is FIFO?**
Imagine a line at a coffee shop:
- First person to join â†’ first person served
- New people join at the **back** (enqueue)
- People leave from the **front** (dequeue)

```
ASCII Visualization:
    enqueue â†’  [5][4][3][2][1] â†’ dequeue
                back       front
                
    Add 6:     [6][5][4][3][2][1]
    Remove:    [6][5][4][3][2]  (1 removed)
```

**API:**
```
Queue<Item>
- Queue()              // create empty queue
- void enqueue(Item)   // add to back
- Item dequeue()       // remove from front
- boolean isEmpty()
- int size()
```

**Implementation Strategies:**

**1. Array-based (Resizing Array):**
```
Concept: Use array with two pointers (head, tail)
Problem: Array can "drift" right, wasting space at left

Solution: Circular array (wrap around using modulo)

[_][_][3][2][1][_]
      â†‘       â†‘
     tail   head
     
After dequeue(1):
[_][_][3][2][_][_]
      â†‘     â†‘
     tail  head
     
After enqueue(4):
[_][_][3][2][_][4]
      â†‘         â†‘
     tail      head (wrapped)
```

**2. Linked List:**
```
Each node points to next:
[1|â†’] â†’ [2|â†’] â†’ [3|â†’] â†’ null
 â†‘                â†‘
head            tail

Enqueue: Add at tail
Dequeue: Remove at head
```

**Performance Analysis:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Operation       â”‚ Resizing    â”‚ Linked List  â”‚ Winner   â”‚
â”‚                 â”‚ Array       â”‚              â”‚          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ enqueue         â”‚ O(1)*       â”‚ O(1)         â”‚ Tie      â”‚
â”‚ dequeue         â”‚ O(1)*       â”‚ O(1)         â”‚ Tie      â”‚
â”‚ Space overhead  â”‚ ~25-50%     â”‚ ~64 bytes/   â”‚ Array    â”‚
â”‚                 â”‚             â”‚  item        â”‚          â”‚
â”‚ Cache locality  â”‚ Excellent   â”‚ Poor         â”‚ Array    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

* amortized (occasionally O(n) during resize)
```

**Mental Model: Choose based on constraints**
- Need minimal space overhead? â†’ Resizing array
- Need guaranteed O(1) per operation? â†’ Linked list
- Real-world recommendation: Resizing array (cache-friendly)

---

#### **1.3.3: Stack (LIFO - Last In First Out)**

**What is LIFO?**
Like a stack of plates:
- Last plate placed on top â†’ first plate removed
- Add to **top** (push)
- Remove from **top** (pop)

```
ASCII Visualization:
    push      [5] â† top        pop
     â†“        [4]               â†‘
             [3]
             [2]
             [1]

Push 6:      [6] â† top
             [5]
             [4]
             ...
             
Pop:         [5] â† top  (6 removed)
             [4]
             ...
```

**API:**
```
Stack<Item>
- Stack()              // create empty stack
- void push(Item)      // add to top
- Item pop()           // remove from top
- Item peek()          // look at top without removing
- boolean isEmpty()
- int size()
```

**Classic Stack Applications:**

**1. Expression Evaluation (Dijkstra's Two-Stack Algorithm)**

Problem: Evaluate `(1 + ((2 + 3) * (4 * 5)))`

```
Algorithm Flow:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Use TWO stacks: one for values, one for ops   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                â”‚
â”‚ 1. Scan left to right                         â”‚
â”‚ 2. If '(': ignore                             â”‚
â”‚ 3. If number: push to value stack             â”‚
â”‚ 4. If operator: push to operator stack        â”‚
â”‚ 5. If ')': pop operator, pop 2 values,        â”‚
â”‚            apply operator, push result        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Example:
Input: (1 + 2)

Values: []
Ops: []

See '(': ignore
Values: []
Ops: []

See '1': push value
Values: [1]
Ops: []

See '+': push op
Values: [1]
Ops: [+]

See '2': push value
Values: [1, 2]
Ops: [+]

See ')': pop op '+', pop values 2,1, compute 1+2=3, push 3
Values: [3]
Ops: []

Result: 3
```

**2. Balanced Parentheses Checking**

```
Input: "{[()]}"  â†’ Valid
Input: "{[(])}"  â†’ Invalid

Algorithm:
- Push opening brackets onto stack
- When closing bracket found:
  - Pop stack
  - Check if it matches
  - If stack empty or mismatch â†’ invalid

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        DECISION TREE                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                          â”‚
â”‚     See character                        â”‚
â”‚          â”‚                               â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”                        â”‚
â”‚    â”‚           â”‚                        â”‚
â”‚ Opening?   Closing?                     â”‚
â”‚    â”‚           â”‚                        â”‚
â”‚  Push      â”Œâ”€â”€â”€â”´â”€â”€â”€â”                   â”‚
â”‚            â”‚       â”‚                   â”‚
â”‚         Stack    Stack                 â”‚
â”‚         empty?   match?                â”‚
â”‚            â”‚       â”‚                   â”‚
â”‚          FAIL    â”Œâ”€â”´â”€â”                â”‚
â”‚                  â”‚   â”‚                â”‚
â”‚                PASS POP                â”‚
â”‚                     continue           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Implementation Comparison:**

```rust
// Rust: Using Vec (stack is just push/pop on vector)
let mut stack: Vec<i32> = Vec::new();
stack.push(5);
stack.push(10);
let top = stack.pop(); // Some(10)
```

```python
# Python: List as stack
stack = []
stack.append(5)
stack.append(10)
top = stack.pop()  # 10
```

```c
// C: Manual array-based stack
typedef struct {
    int items[100];
    int top;
} Stack;

void push(Stack* s, int val) {
    s->items[++s->top] = val;
}

int pop(Stack* s) {
    return s->items[s->top--];
}
```

```cpp
// C++: std::stack
#include <stack>
std::stack<int> s;
s.push(5);
s.push(10);
int top = s.top(); // 10
s.pop();
```

```go
// Go: Slice as stack
stack := make([]int, 0)
stack = append(stack, 5)
stack = append(stack, 10)
top := stack[len(stack)-1]
stack = stack[:len(stack)-1]
```

---

### **Chapter 1.4: Analysis of Algorithms**

**The Central Question:**
*"Will my program be able to solve a large practical input?"*

Not just "does it work?" but "does it work **fast enough** on **real data**?"

#### **1.4.1: The Scientific Method**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      PERFORMANCE ANALYSIS FRAMEWORK            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                â”‚
â”‚  1. OBSERVE: Run experiments, measure time    â”‚
â”‚      â†“                                         â”‚
â”‚  2. HYPOTHESIZE: Form a model (e.g., ~NÂ²)     â”‚
â”‚      â†“                                         â”‚
â”‚  3. PREDICT: What happens if N doubles?       â”‚
â”‚      â†“                                         â”‚
â”‚  4. VERIFY: Run larger experiments            â”‚
â”‚      â†“                                         â”‚
â”‚  5. VALIDATE: Does reality match theory?      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Example: 3-Sum Problem**

*Problem:* Given N integers, count how many triples sum to 0.

**Brute Force Approach:**
```
for i in 0..N:
    for j in i+1..N:
        for k in j+1..N:
            if arr[i] + arr[j] + arr[k] == 0:
                count++
```

**Analysis:**
- Three nested loops
- Inner loop executes ~NÂ³ times
- Expected: O(NÂ³) complexity

**Empirical Validation:**
```
N      Time (seconds)    Ratio
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1000   0.1               -
2000   0.8               8.0
4000   6.4               8.0
8000   51.2              8.0

Ratio â‰ˆ 8 = 2Â³
Conclusion: Confirmed cubic (NÂ³) growth
```

**Key Insight:**
Doubling N multiplies time by 2^b where b is exponent in complexity.
- If O(N): ratio = 2
- If O(N log N): ratio â‰ˆ 2 (slightly more)
- If O(NÂ²): ratio = 4
- If O(NÂ³): ratio = 8

---

#### **1.4.2: Order-of-Growth Classifications**

**What is "Order of Growth"?**
How running time **scales** as input size N increases.

```
Common Complexity Classes (Best to Worst):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Complexity   â”‚ Name        â”‚ N=1000 â†’ N=2000     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ O(1)         â”‚ Constant    â”‚ Same time            â”‚
â”‚ O(log N)     â”‚ Logarithmic â”‚ +1 operation         â”‚
â”‚ O(N)         â”‚ Linear      â”‚ 2x time              â”‚
â”‚ O(N log N)   â”‚ Linearith.  â”‚ ~2x time             â”‚
â”‚ O(NÂ²)        â”‚ Quadratic   â”‚ 4x time              â”‚
â”‚ O(NÂ³)        â”‚ Cubic       â”‚ 8x time              â”‚
â”‚ O(2^N)       â”‚ Exponential â”‚ Infeasible!          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Visualization:**
```
Time
 â”‚
 â”‚                                          â•± O(2^N)
 â”‚                                      â•±â•±â•±
 â”‚                               â•±â•±â•±â•±â•±â•±
 â”‚                        â•±â•±â•±â•±â•±â•±â•±  O(NÂ³)
 â”‚                 â•±â•±â•±â•±â•±â•±â•±
 â”‚          â•±â•±â•±â•±â•±â•±â•±  O(NÂ²)
 â”‚     â•±â”€â”€â”€â”€â”€â”€â”€â”€â”€  O(N log N)
 â”‚  â•±â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ O(N)
 â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ O(log N)
 â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ O(1)
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ N
```

**Practical Guidelines:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MAXIMUM PROBLEM SIZE FOR 1 SECOND EXECUTION  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ O(log N)     â”‚ Any practical N                 â”‚
â”‚ O(N)         â”‚ ~10^9                           â”‚
â”‚ O(N log N)   â”‚ ~10^7-10^8                      â”‚
â”‚ O(NÂ²)        â”‚ ~10^4                           â”‚
â”‚ O(NÂ³)        â”‚ ~500                            â”‚
â”‚ O(2^N)       â”‚ ~20-25                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Mental Model: Scalability Threshold**
Ask yourself: "If N doubles, can I still solve it in reasonable time?"
- O(NÂ²): Maybe for N=10,000, but not N=1,000,000
- O(N log N): Yes, even for N=10^8

---

#### **1.4.3: Memory Usage**

**Typical Object Overhead (Java/C++/Python):**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Type                â”‚ Bytes    â”‚ Notes      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ boolean             â”‚ 1        â”‚            â”‚
â”‚ byte                â”‚ 1        â”‚            â”‚
â”‚ char                â”‚ 2        â”‚            â”‚
â”‚ int                 â”‚ 4        â”‚            â”‚
â”‚ float               â”‚ 4        â”‚            â”‚
â”‚ long                â”‚ 8        â”‚            â”‚
â”‚ double              â”‚ 8        â”‚            â”‚
â”‚ Reference           â”‚ 8        â”‚ 64-bit sys â”‚
â”‚ Array overhead      â”‚ 24       â”‚ + padding  â”‚
â”‚ Object overhead     â”‚ 16       â”‚            â”‚
â”‚ Padding             â”‚ 0-7      â”‚ Multiple 8 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Example: Linked List Node**
```java
class Node {
    int val;      // 4 bytes
    Node next;    // 8 bytes (reference)
    // Object overhead: 16 bytes
    // Total: 16 + 4 + 8 = 28 â†’ padded to 32 bytes
}
```

**Memory vs Speed Tradeoff:**
- Array: Dense (cache-friendly), but fixed size
- Linked List: Flexible size, but pointer overhead

---

### **Chapter 1.5: Union-Find (Disjoint Set Union)**

**The Problem:**
*"Given a set of objects, support two operations:"*
1. **Union**: Connect two objects
2. **Find**: Are two objects connected?

**Real-World Applications:**
- Network connectivity (computers, social networks)
- Image processing (connected components)
- Kruskal's MST algorithm (coming later!)

**Example:**
```
Initial: {0} {1} {2} {3} {4} {5}  (all separate)

union(0, 1): {0,1} {2} {3} {4} {5}
union(2, 3): {0,1} {2,3} {4} {5}
union(1, 3): {0,1,2,3} {4} {5}

connected(0, 3)? â†’ YES (same component)
connected(0, 4)? â†’ NO (different components)
```

**API:**
```
UnionFind
- UF(int N)              // initialize N sites
- void union(int p, int q) // connect p and q
- boolean connected(int p, int q) // are p,q connected?
- int find(int p)         // component identifier for p
- int count()             // number of components
```

---

#### **Evolution of Solutions:**

**Approach 1: Quick-Find (Eager)**

**Idea:** 
Each element stores its component ID directly.

```
Array representation:
Index:  0  1  2  3  4  5
Value: [1][1][3][3][4][5]
        â†‘       â†‘
     Component 1  Component 3
```

**Operations:**
- **find(p)**: Just return `id[p]` â†’ O(1)
- **union(p, q)**: Change all elements with `id[p]` to `id[q]` â†’ O(N)

**Problem:** Union is too slow! For N unions: O(NÂ²) total

---

**Approach 2: Quick-Union (Lazy)**

**Idea:** 
Each element points to a parent. Root is component ID.

```
Tree representation:
    1           3
   / \         / \
  0   2       4   5

Array (parent pointers):
Index:  0  1  2  3  4  5
Parent:[1][1][1][3][3][3]
```

**Operations:**
- **find(p)**: Follow parent pointers to root
  ```
  while (p != parent[p]):
      p = parent[p]
  return p
  ```
- **union(p, q)**: Set root of p to point to root of q

**Performance:** 
- Best case: O(1) per operation
- Worst case: O(N) if tree becomes tall (linear chain)

---

**Approach 3: Weighted Quick-Union**

**Key Insight:** 
Avoid tall trees by always attaching smaller tree under larger tree.

```
Before union(small_tree, large_tree):
  
  Small:     Large:
    3          1
    |         /|\
    4        0 2 5
    |            |
    6            7

After union (attach small under large):
        1
       /|\
      0 2 5   3
          |   |
          7   4
              |
              6
```

**Track tree sizes:**
```
Index:  0  1  2  3  4  5  6  7
Parent:[1][1][1][1][3][1][4][5]
Size:  [1][5][1][3][1][1][1][1]  (only meaningful at roots)
```

**Performance:** 
- find: O(log N) worst case (tree depth â‰¤ log N)
- union: O(log N) worst case

**Why log N depth?**
When you union two trees, the depth increases only when equal-sized trees merge. Each merge doubles size, so depth = logâ‚‚(size).

---

**Approach 4: Path Compression (Ultimate Optimization)**

**Key Insight:** 
After finding root, make every node point directly to root.

```
Before find(6):
    1
   / \
  2   3
     /
    4
   /
  5
 /
6

After find(6) with path compression:
      1
    / | \  \
   2  3  4  5  6  (all point directly to root!)
```

**Implementation:**
```rust
fn find(&mut self, mut p: usize) -> usize {
    let root = {
        let mut current = p;
        while current != self.parent[current] {
            current = self.parent[current];
        }
        current
    };
    
    // Path compression: make p point directly to root
    while p != root {
        let next = self.parent[p];
        self.parent[p] = root;
        p = next;
    }
    
    root
}
```

**Performance with Path Compression + Weighting:**
- Amortized: O(Î±(N)) per operation
  - Î±(N) = inverse Ackermann function
  - For all practical N: Î±(N) â‰¤ 5
  - **Essentially constant time!**

---

**Performance Summary:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Algorithm            â”‚ union    â”‚ find     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Quick-Find           â”‚ O(N)     â”‚ O(1)     â”‚
â”‚ Quick-Union          â”‚ O(N)*    â”‚ O(N)*    â”‚
â”‚ Weighted QU          â”‚ O(log N) â”‚ O(log N) â”‚
â”‚ Weighted + Path Comp â”‚ O(Î±(N))  â”‚ O(Î±(N))  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
* worst case
```

**Mental Model: Optimization Pattern**
1. Start with simple solution
2. Identify bottleneck
3. Add invariant to prevent worst case (weighting)
4. Add online optimization (path compression)

This pattern repeats throughout algorithms!

---

## **Cognitive Break: Deliberate Practice Framework**

Before continuing, let's discuss **how to practice** these concepts:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           DELIBERATE PRACTICE CYCLE              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚  1. FOCUS: Pick ONE concept (e.g., Quick-Union) â”‚
â”‚      â†“                                           â”‚
â”‚  2. IMPLEMENT: Code it without looking          â”‚
â”‚      â†“                                           â”‚
â”‚  3. TEST: Run on examples, edge cases           â”‚
â”‚      â†“                                           â”‚
â”‚  4. ANALYZE: What was hard? What did I miss?    â”‚
â”‚      â†“                                           â”‚
â”‚  5. REFINE: Fix mistakes, optimize              â”‚
â”‚      â†“                                           â”‚
â”‚  6. TEACH: Explain it to rubber duck            â”‚
â”‚      â†“                                           â”‚
â”‚  7. APPLY: Solve related LeetCode problem       â”‚
â”‚      â†“                                           â”‚
â”‚  8. REFLECT: What patterns emerged?             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Spaced Repetition:**
- Day 1: Learn Union-Find
- Day 3: Implement from memory
- Day 7: Solve 3 problems using it
- Day 14: Teach it to someone
- Day 30: Review and solve harder variant

---

## ğŸ“– **PART II: SORTING**

Sorting is **fundamental** because:
1. Many problems become easier with sorted data
2. Teaches algorithm design principles
3. Performance analysis matters (NÂ² vs N log N is huge!)

### **Chapter 2.1: Elementary Sorts**

#### **2.1.1: Selection Sort**

**The Idea:**
Find the minimum element, swap it to the front. Repeat for remaining elements.

```
Visualization:
Initial: [5, 2, 8, 1, 9]
         
Step 1: Find min (1), swap with first
        [1 | 2, 8, 5, 9]
         â†‘ sorted

Step 2: Find min in [2,8,5,9] â†’ 2, already in place
        [1, 2 | 8, 5, 9]
            â†‘ sorted

Step 3: Find min in [8,5,9] â†’ 5, swap with 8
        [1, 2, 5 | 8, 9]
               â†‘ sorted

Step 4: Find min in [8,9] â†’ 8, already in place
        [1, 2, 5, 8 | 9]
                  â†‘ sorted

Done!
```

**Algorithm Flow:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  for i = 0 to N-1:                    â”‚
â”‚      min_idx = i                       â”‚
â”‚      for j = i+1 to N:                 â”‚
â”‚          if arr[j] < arr[min_idx]:     â”‚
â”‚              min_idx = j               â”‚
â”‚      swap(arr[i], arr[min_idx])        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Implementation (Rust):**
```rust
fn selection_sort<T: Ord>(arr: &mut [T]) {
    let n = arr.len();
    for i in 0..n {
        let mut min_idx = i;
        for j in (i + 1)..n {
            if arr[j] < arr[min_idx] {
                min_idx = j;
            }
        }
        arr.swap(i, min_idx);
    }
}
```

**Performance Analysis:**
- **Comparisons:** (N-1) + (N-2) + ... + 1 = N(N-1)/2 â‰ˆ NÂ²/2
- **Swaps:** Exactly N-1 (one per outer loop)
- **Time Complexity:** O(NÂ²) - quadratic
- **Space Complexity:** O(1) - in-place
- **Stable?** No (can swap equal elements out of order)

**Characteristics:**
- âœ… Simple to understand
- âœ… Minimal swaps (good if swaps are expensive)
- âœ… Works well on small arrays
- âŒ Quadratic time (slow for large N)
- âŒ Doesn't adapt to partially sorted data

---

#### **2.1.2: Insertion Sort**

**The Idea:**
Like sorting cards in your hand. Take each element, insert it into correct position among previously sorted elements.

```
Visualization:
Initial: [5, 2, 8, 1, 9]

Step 1: [5] already sorted
        [5 | 2, 8, 1, 9]

Step 2: Insert 2 into sorted part
        [2, 5 | 8, 1, 9]

Step 3: Insert 8 (already in place)
        [2, 5, 8 | 1, 9]

Step 4: Insert 1
        [1, 2, 5, 8 | 9]

Step 5: Insert 9 (already in place)
        [1, 2, 5, 8, 9]
```

**Algorithm Flow:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  for i = 1 to N-1:                    â”‚
â”‚      key = arr[i]                      â”‚
â”‚      j = i - 1                         â”‚
â”‚      while j >= 0 and arr[j] > key:    â”‚
â”‚          arr[j+1] = arr[j]             â”‚
â”‚          j--                           â”‚
â”‚      arr[j+1] = key                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

